<!DOCTYPE html>
<html>
  <head lang="ko">

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>뉴럴 네트워크와 딥러닝</title>

    <link href="assets/style.css" rel="stylesheet">

    <!-- mathjax -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>
    
    <!-- jQuery -->
    <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <!-- google code-prettify -->
    <script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>  

  </head>
    
  <body>
    
    <div class="header">
      <h1>뉴럴 네트워크와 딥러닝</h1>
      <h3>Original Edition: <a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a> by <a href="http://michaelnielsen.org/">Michael A. Nielsen</a></h3>
    </div>
    
    <div class="topnav">
      <a href="#">tmpLink</a>
      <a href="#">tmpLink</a>
      <a href="#">tmpLink</a>
      <a href="https://github.com/sihyeon-kim/neural-networks-and-deep-learning-korean" style="float:right">
        <img src="images/GitHub-Mark-32px.png" widthe="19" height="19">
        &nbsp;Edit on translator's Github
      </a>
    </div>

    
    
    <div class="row">

      <!--
      <div class="sidebar">
        <a class="active" href="#home">Home</a>
        <a href="#news">News</a>
        <a href="#contact">Contact</a>
        <a href="#about">About</a>
      </div>
      -->

      <div class="sidebar">
        <div class="card">
          <a href="index.html">뉴럴 네트워크와 딥러닝</a>
          <a href="aboutBook.html">&nbsp;&nbsp;&nbsp;&nbsp;이 책에 대하여</a>
          <a href="onExercises.html">&nbsp;&nbsp;&nbsp;&nbsp;연습문제에 대하여</a>
          <a class="active" href="chapter1.html">뉴럴 네트워크를 이용하여 손으로 쓴 숫자 인식하기</a>
          <a href="chapter2.html">역전파 알고리즘 동작 방법</a>
          <a href="chapter3.html">뉴럴 네트워크의 학습 방법 향상하기</a>
          <a href="chapter4.html">모든 함수를 계산할 수 있는 뉴럴 네트워크 증명</a>
          <a href="chapter5.html">딥 뉴럴 네트워크를 학습시키기 어려운 이유</a>
          <a href="chapter6.html">딥러닝</a>
          <a href="appendix.html">부록: 지능을 위한 단순한 알고리즘</a>
          <a href="acknowledgements.html">감사의 말</a>
          <a href="faq.html">질문과 답변</a>
        </div>
      </div>

      <div class="leftcolumn">
        <div class="card">
          <h1>1장</h1>
          <h1>신경망을 이용한 손글씨 숫자 인식</h1>
          <hr>

          <p>
            인간의 시각 시스템은 불가사의하다. 
            아래에 있는 손글씨를 한번 보자. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/digits.png" alt="digits" width="200px">
            <br /><br />
            대부분의 사람은 504192라는 숫자를 아무런 노력 없이 알 수 있다.
            너무 쉬워서 장난하는 것처럼 느껴진다. 
            인간의 좌뇌와 우뇌에는 일차 시각 피질이 있고 이를 V1이라 부른다. 
            14억 개의 뉴런이 일차 시각 피질을 구성하며 뉴런 사이에는 수십억 개의 연결 통로가 있다.
            V1뿐만 아니라 V2와 V3, V4, V5와 같은 일련의 피질들이 시각 시스템을 구성해서 더 복잡한 이미지를 처리한다. 
            인간은 시각적인 세상을 이해하기 위해 수억 년에 걸쳐 진화한 슈퍼컴퓨터를 머리에 지니고 다니는 셈이다. 
            손글씨 숫자를 인식하는 것은 어려운 일이지만, 
            인간은 놀라울 정도로 눈으로 본 것을 잘 이해한다. 
            그리고 거의 모든 과정은 무의식적으로 일어나서 
            시각 시스템이 얼마나 어려운 문제를 푸는지 가늠하기 어렵다. 
          </p>

          <p>
            숫자를 인식하는 컴퓨터 프로그램을 작성할 때 시각적인 패턴 인식의 어려움은 분명해진다. 
            눈으로 보고 이해할 때는 쉬웠던 문제가 갑자기 어렵게 느껴진다. 
            단순히 직감을 이용해 모양을 인식하는 방법을 다음과 같이 생각해보자. 
            "숫자 9는 위에 고리가 있고, 오른쪽에 수직선이 있다." 
            이러한 방식으로 알고리즘을 작성하기는 쉽지 않다. 
            위와 같은 규칙들을 정확하게 만들려고 할수록 수많은 예외의 늪에 빠지고 만다. 
            이는 정말 절망적이다. 
          </p>

          <p>
            신경망(neural network)은 다른 방식으로 문제에 접근한다. 
            기본적인 아이디어는 학습 데이터(training examples)라 부르는 수많은 손글씨 숫자를 학습할 수 있는 시스템을 개발하는 것이다. 
            
            <br /><br />
            <img class="contentimg" src="./images/chapter1/mnist_100_digits.png" alt="digits" width="400px">
            <br /><br />

            다시 말해 신경망은 데이터를 활용하여 손글씨를 인식하는 규칙을 스스로 추론한다. 
            게다가 신경망은 학습 데이터 세트의 수가 많을수록 손글씨를 많이 학습할 수 있으며 그에 따라 정확도가 향상된다. 
            위 그림에는 100개의 학습 데이터가 있지만, 수천 개 혹은 수백만 개로 늘려 더 좋은 손글씨 인식기를 만들 수 있다.  
          </p>
          
          <p>
            1장에서는 손글씨 숫자를 인식하는 방법을 학습하는 신경망 프로그램을 구현해볼 것이다. 
            프로그램의 코드는 단 74줄뿐이며 신경망과 관련된 다른 라이브러리는 사용하지 않는다. 
            짧은 프로그램이지만 손글씨 숫자 인식의 정확도는 96%가 넘고 인간이 개입할 필요가 없다. 
            책의 뒷부분에서는 정확도가 99%를 넘는 인식기를 만들어 보겠다. 
            실제 상업적으로 이용하는 신경망의 성능은 아주 좋아서  
            은행에서는 신경망을 이용해 수표를 처리하고, 우체국에서는 주소를 인식하기 위해 신경망을 이용하고 있다. 
          </p>

          <p>
            신경망을 공부할 수 있는 훌륭한 예제인 손글씨 인식 문제를 집중적으로 살펴보겠다.   
            손글씨 숫자 인식 문제가 쉬운 것은 아니지만 그렇다고 복잡한 해결책을 필요로하거나 엄청난 계산 능력을 요구하는 것도 아니다. 
            게다가 심층학습(deep learning) 같은 심화한 기술로 발전시키기에 좋은 예제이다. 
            그래서 책 전반에 걸쳐 손글씨 인식 문제를 다룰 것이다. 
            책의 뒷부분에서 손글씨를 인식하는 아이디어가 컴퓨터 비전과 음성 인식, 자연어 처리와 같은 다른 분야의 문제에 어떻게 적용되는지 살펴보겠다. 
          </p>

          <p>
            1장에서 손글씨 숫자를 인식하는 프로그램을 작성하는 방법만 다루었다면 내용은 훨씬 더 짧았을 것이다. 
            하지만 그 과정에서 얻을 수 있는 신경망에 대한 핵심 아이디어를 살펴볼 것이다. 
            인공 뉴런 중 중요한 두 가지인 퍼셉트론과 시그모이드 뉴런 그리고 신경망에 대한 표준 학습 알고리즘인 확률적 경사 하강법을 알아보겠다. 
            전반적으로 핵심 아이디어가 <i>왜</i> 그런 방식으로 동작하는지 설명하고 신경망에 대한 직관력을 키우는데 초점을 맞추겠다. 
            기본적인 동작 원리만 설명하는 것보다 설명이 길어질 수 있지만 심도있게 이해할 가치가 충분히 있다. 
            1장의 끝부분에 도달하면 심층학습이 무엇인지, 왜 중요하지 이해할 수 있을 것이다. 
          </p>

          <br />
          <h2>퍼셉트론</h2>
          <hr>
          
          <p>
            신경망이란 무엇일까? 
            먼저 인공 뉴런의 한 종류인 <i>퍼셉트론(perceptron)</i>에 대해 알아보자. 
            1950년대와 1960년대에 과학자 <a href="https://en.wikipedia.org/wiki/Frank_Rosenblatt">프랭크 로젠블랫</a>(Frank Rosenblatt)은 
            <a href="https://en.wikipedia.org/wiki/Warren_Sturgis_McCulloch">워렌 맥컬로치</a>(Warren McCulloch)와 
            <a href="https://en.wikipedia.org/wiki/Walter_Pitts">월터 피츠</a>(Walter Pitts)의 <a href="https://scholar.google.ca/scholar?cluster=4035975255085082870">논문</a>에 영감을 받아 퍼셉트론을 <a href="https://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ&hl=ko">고안</a>했다. 
            최근에는 인공 뉴런의 다른 모델을 더 많이 사용한다. 
            신경망에 관한 최근 논문과 이 책에서 주로 사용하는 뉴런 모델은 <i>시그모이드 뉴런(sigmoid neuron)</i>이다. 
            곧 시그모이드 뉴런에 대해 살펴보겠지만 시그모이드 뉴런을 공부하기에 앞서 퍼셉트론을 이해해야 한다. 
          </p>

          <p>
            그렇다면 퍼셉트론은 어떻게 동작할까? 
            퍼셉트론은 여러 개의 이진 입력 $x_1, x_2, \ldots$ 을 받아 하나의 이진 값을 출력한다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz0.png" alt="digits" width="300px">
            <br /><br /> 
            위의 그림에서 퍼셉트론은 세 개의 변수 $x_1, x_2, x_3$ 을 입력받는다. 
            일반적으로 입력의 개수는 더 많을수도 있고 더 적을수도 있다. 
            로젠블랫은 출력을 계산하는 간단한 규칙을 제안했다. 
            로젠블랫은 실수(real number)이면서 출력에 대한 각 입력의 중요성을 나타내는 <i>가중치(weight)</i> $w_1,w_2,\ldots$를 도입했다.  
            가중치 합 $\sum_j w_j x_j$ 이 <i>역치(threshold value)</i>보다 큰지 작은지에 따라 뉴런은 0 또는 1을 출력한다. 
            가중치처럼 역치는 실수이고 뉴런의 파라미터(parameter)이다. 
            수학적으로 정확하게 나타내면 아래와 같다.

            $$\begin{eqnarray}
            \mbox{output} & = & \left\{ \begin{array}{ll}
                0 & \mbox{if } \sum_j w_j x_j \leq \mbox{ threshold} \\
                1 & \mbox{if } \sum_j w_j x_j > \mbox{ threshold}
                \end{array} \right.
            \tag{1}\end{eqnarray}$$
            
            이것이 바로 퍼셉트론이 동작하는 방식이다. 
          </p>

          <p>
            퍼셉트론은 기본적인 수학 모델이다. 
            퍼셉트론은 입력에 가중치를 매겨 결정을 내리는 장치이다. 
            예를 들어 보자. 
            현실적이지는 않지만 이해하기 쉬운 예를 먼저 들고 나중에 조금 더 현실적인 예를 다루어 보자. 
            다가오는 주말에 당신이 사는 곳에서 치즈 페스티벌이 열린다고 가정하자.  
            당신은 치즈를 좋아하기 때문에 페스티벌에 갈지 말지 결정해야 한다. 
            당신은 세 가지 요소를 가늠하여 결정을 내릴 수 있다. 
            <ol>
                <li>날씨가 좋은가?</li>
                <li>당신의 이성 친구가 함께 가고 싶어 하는가?</li>
                <li>대중교통을 이용해 페스티벌에 갈 수 있는가? (자가용이 없다고 생각하자)</li>
            </ol>
            세 가지 요소를 이진 변수 $x_1, x_2, x_3$로 표현할 수 있다. 
            예를 들어 날씨가 좋으면 $x_1 = 1$ 날씨가 좋지 않으면 $x_1 = 0$으로 나타낼 수 있다. 
            비슷한 방법으로 이성 친구가 함께 가길 원하면 $x_2 = 1$로 그렇지 않다면 $x_2 = 0$ 으로 나타내자. 
            대중교통에 대해서도 같은 방법으로 $x_3$을 표현할 수 있다. 
          </p>

          <p>
            이제 당신이 치즈를 많이 좋아한다고 가정하자. 
            당신이 치즈를 많이 좋아하여 이성 친구가 함께 가지 않고 대중교통을 이용해서 가기 어려워도 페스티벌에 가고 싶어 한다고 가정해보자. 
            하지만 당신은 날씨에 민감하여 날씨가 안 좋으면 페스티벌에 가지 않는다고 가정하자. 
            이런 종류의 의사 결정을 모델링하기 위해 퍼셉트론을 이용할 수 있다. 
            날씨에 대한 가중치 $w_1 = 6$으로 설정하고, 
            다른 조건에 대한 가중치를 각각 $w_2 = 2, w_3 = 2$로 설정하여 모델링한다. 
            가중치 $w_1$의 값이 커질수록 당신에게 이성 친구의 동행 여부와 대중교통의 편리성보다 날씨가 중요해진다. 
            마지막으로 퍼셉트론에 대한 역치를 $5$로 정했다고 가정하자. 
            이렇게 가중치를 선택하면 날씨가 좋은 경우 퍼셉트론의 출력은 1이 되고 날씨가 나쁜 경우 0이 된다. 
            이는 우리가 원하는 의사 결정 모델을 구현하는 퍼셉트론이다. 
            이성 친구의 동행 여부와 대중교통의 편리성은 출력에 영향을 주지 않는다. 
          </p>

          <p>
            가중치와 역치를 바꿔서 다른 의사 결정 모델을 만들 수 있다. 
            예를 들어 역치가 3이라고 가정하자. 
            그러면 날씨가 좋을 때 페스티벌에 가거나 
            이성 친구가 함께 가고 대중교통이 가까이 있는 경우에 페스티벌에 가야 하는 퍼셉트론이 된다. 
            즉 다른 의사 결정 모델이 됩니다. 
            역치가 낮으면 당신이 페스티벌에 가는 경우는 더 많아진다. 
          </p>

          <p>
            퍼셉트론은 완전한 의사 결정 모델이 아니다. 
            하지만 예시에서 보여주는 것은 퍼셉트론이 의사 결정을 하기 위해 서로 다른 요소를 가늠하는 방법이다.  
            그리고 복잡한 퍼셉트론 네트워크는 섬세한 의사 결정을 할 수 있는 것 같다. 
            
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz1.png" alt="digits" width="500px">
            <br /><br /> 

            네트워크에서 첫 번째 퍼셉트론 열(column)은 첫 번째 <i>층(layer)</i>이라고 부른다. 
            네트워크에서 퍼셉트론의 첫 번째 열은 입력을 고려하여 세 개의 결정을 내린다. 
            퍼셉트론의 두 번째 층은 어떨까? 
            두 번째 층에 있는 각각의 퍼셉트론은 첫 번째 층의 의사결정 결과를 고려하여 결정을 내린다. 
            이런 방식으로 두 번째 층에 있는 퍼셉트론은 첫 번째 층에 있는 퍼셉트론보다 더 복잡하고 추상적인 결정을 할 수 있다. 
            그리고 훨씬 더 복잡한 결정은 세 번째 층에 있는 퍼셉트론이 한다. 
            이러한 방식으로 다층 퍼셉트론 네트워크는 수준 높은 의사 결정에 참여할 수 있다.
          </p>

          <p>check!!</p>

          <p>
            퍼셉트론을 정의할 때 하나의 퍼셉트론은 하나의 출력을 가진다고 정의했습니다. 
            위의 그림에서 본 퍼셉트론 네트워크는 여러 개의 출력을 가지는 것처럼 보입니다. 
            사실 위의 퍼셉트론도 하나의 출력을 가집니다. 
            여러 개의 출력 화살표는 단지 하나의 퍼셉트론의 출력이 여러 개의 다른 퍼셉트론의 입력으로 사용될 수 있다는 것을 나타내는 유용한 방법입니다. 
            하나의 화살표가 나누어 지는 것을 그리는 것보다 편한 방법입니다.
          </p>

          <p>
            퍼셉트론을 나타내는 방법을 간단히 해보겠습니다. 
            조건 $\sum_j w_j x_j > \mbox{threshold}$을 간단하게 나타내기 위해 두 가지 표기를 바꿀 수 있습니다. 
            첫 번째 변화는 $\sum_j w_j x_j$을 내적으로 표현하는 겁니다. 
            내적으로 표현하면 $w \cdot x \equiv \sum_j w_j x_j$이고, $w$와 $x$는 성분이 각각 가중치와 입력인 벡터입니다. 
            두 번째 변화는 역치를 부등식의 좌변으로 옮겨 퍼셉트론의 바이어스 $b \equiv -\mbox{threshold}$로 치환하는 방법입니다. 
            역치 대신에 편향을 사용해서 퍼셉트론 규칙을 다시 쓰면 다음과 같습니다. 
            $$\begin{eqnarray}
            \mbox{output} = \left\{ 
              \begin{array}{ll} 
                0 & \mbox{if } w\cdot x + b \leq 0 \\
                1 & \mbox{if } w\cdot x + b > 0
              \end{array}
            \right.
            \tag{2}\end{eqnarray}$$
            그러면 편형을 퍼셉트론의 출력이 1이 되기 쉬운 정도로 볼 수 있습니다. 
            또는 생물학적인 용어를 사용하면 편향을 퍼셉트론이 활동하는게 얼마나 쉬운지 나타냅니다. 
            퍼셉트론이 큰 편향을 가지면 퍼셉트론의 출력이 1이되기 엄청 쉽습니다. 
            하지만 편향이 매우 작은 음수인 경우 퍼셉트론의 출력이 1이 되기 매우 어렵습니다. 
            퍼셉트론은 표현하는데 편향을 도입한 것은 분명히 작은 변화이지만 나중에 표기의 단순함을 이끌어 낼 것입니다. 
            이로 인해 책의 나머지 부분에서는 역치를 사용하지 않고 편향을 사용합니다.
          </p>

          <p>
            퍼셉트론은 결정을 내리기 위한 증거를 고려하는 방법입니다. 
            퍼셉트론을 이용하면 AND, OR, NANd와 같은 기초적인 논리 함수도 계산할 수 있습니다. 
            예를 들어, 두 개의 입력을 가지고 가중치가 각각 $-2$이고 편향이 $3$인 퍼셉트론이 있다고 가정해보겠습니다. 
            퍼셉트론을 그려보면 아래와 같습니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz2.png" alt="digits" width="300px">
            <br /><br /> 
            그러면 입력이 $00$이면 $(-2)*0+(-2)*0+3 = 3$으로 양수이므로 출력은 $1$입니다. 
            여기서 $*$기호는 곱셈을 나타냅니다. 
            비슷한 방법으로 입력이 $01$이나 $10$이면 출력은 $1$입니다. 
            하지만 입력이 $11$인 경우 $(-2)*1+(-2)*1+3 = -1$은 음수이므로 출력은 $0$입니다. 
            그리고 이 퍼셉트론은 NAND 게이트입니다. 
          </p>

          <p>
            NAND 게이트 예시를 통해 퍼셉트론을 이용한 간단한 논리 함수를 계산을 보여주었습니다. 
            사실 퍼셉트론 네트워크를 이용하면 어떤 논리 함수도 구현할 수 있습니다. 
            NAND 게이트는 범용 게이트이므로 어떠한 계산도 NAND 게이트를 통해 할 수 있습니다. 
            예를 들어, NAND 게이트를 이용해서 두 개의 비트 $x_1, x_2$를 더하는 회로를 만들 수 있습니다. 
            이는 비트 합 $x_1 \oplus x_2$과 $x_1$과 $x_2$가 모두 1일 때 1이되는 자리 올림 비트가 필요합니다. 
            자리 올림 비트는 비트 곱 $x_1 x_2$으로 쓸 수 있습니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz3.png" alt="digits" width="500px">
            <br /><br /> 
            동등한 퍼셉트론 네트워크를 구하려면 모든 NAND 게이트를 퍼셉트론으로 치환합니다. 
            각 퍼셉트론은 두 개의 입력을 가지고 가중치는 $-2$이며 전체 편향은 $3$입니다. 
            아래 결과 네트워크를 그렸습니다. 
            도표에서 화살표를 쉽게 그리기위해 오른쪽 아래의 NAND 게이트위치에 상응하는 퍼셉트론을 조금 옮겨 그렸습니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz4.png" alt="digits" width="500px">
            <br /><br />
            위에 나타난 퍼셉트론 네트워크에서 주목할만한 점은 가장 왼쪽에 있는 퍼셉트론의 출력이 가장 아래 있는 퍼셉트론의 입력에 두 번 사용된다는 점입니다. 
            퍼셉트론을 정의할 때 출력 두 개가 중복으로 같은 입력으로 사용될 수 있는지 말하지 않았습니다. 
            사실 그렇게 중요한 문제는 아닙니다. 
            두 개의 출력선 각각은 가중치 $-2$를 가지기 때문에 두 개의 출력선을 하나로 합쳐 나타낸 뒤 가중치를 $-4$로 나타낼 수 있습니다. 
            퍼셉트론 네트워크를 아래처럼 다시 그릴 수 있습니다. 표시하지 않은 가중치는 $-2$이고, 편향은 모두 $3$입니다. 하나의 가중치 $-4$는 표시하였습니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz5.png" alt="digits" width="500px">
            <br /><br />
            지금까지 입력 변수 $x_1, x_2$를 퍼셉트론 네트워크 왼편에 표시했습니다. 
            사실 입력을 인코딩하는 입력 층을 그리는 것이 관습입니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz6.png" alt="digits" width="500px">
            <br /><br />
            입력 퍼셉트론에 대한 표기법으로 출력은 그리고, 입력은 없어도 됩니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz7.png" alt="digits" width="150px">
            <br /><br />
            입력이 없는 퍼셉트론을 의미하는 것은 아닙니다. 
            입력이 없는 퍼셉트론이라고 가정하면 가중치 합 $\sum_j w_j x_j$은 항상 0이 되고, $b > 0$이면 출력은 1 $b \leq 0$이면 출력은 0이 됩니다. 
            즉 이 퍼셉트론의 출력은 고정된 값을 가지고 원하는 출력 값(위 예에서 $x_1$)을 얻을 수 없습니다. 
            입력 퍼셉트론은 퍼셉트론이 아니라 원하는 출력 값 $x_1, x_2,\ldots$을 가지는 특별한 단위로 생각하면 됩니다. 
          </p>

          <p>
            덧셈기 예제는 퍼셉트론 네트워크가 많은 수의 NAND 게이트를 포함한 회로에 어떻게 사용되는지 보여줍니다. 
            그리고 NAND 게이트는 범용 게이트이므로 퍼셉트론 또한 범용적으로 사용할 수 있습니다. 
          </p>

          <p>
            퍼셉트론의 범용성은 다행스럽기도 하고 실망스럽기도 합니다.  
            다행인 점은 퍼셉트론 네트워크가 어떤 계산 장치보다 강력한 기능을 할 수 있습니다. 
            하지만 퍼셉트론이 단시 새로운 형태의 NAND 게이트라는 점은 실망스럽습니다. 이는 전혀 새로운 뉴스가 아닙니다. 
          </p>

          <p>
            하지만 이러한 관점이 제시하는 상황은 많이 달라졌습니다. 
            인공 뉴런 네트워크의 가중치와 편향 값을 자동으로 조정하는 학습 알고리즘을 고안할 수 있다는 사실이 밝혀졌습니다. 
            이러한 조정은 프로그래머가 아닌 외부 자극에 대한 반응으로 일어납니다. 
            학습 알고리즘 덕분에 우리는 인공 뉴런을 전통적인 논리 게이트와 다른 방식으로 사용할 수 있습니다. 
            NAND와 다른 게이트를 사용한 회로 대신에 뉴럴 네트워크는 문제를 풀기 위해 학습을 할 수 있습니다. 
            때로는 직접 회로를 설계하기 어려운 문제들도 풀 수 있습니다. 
          </p>

          <br />
          <h2>시그모이드 뉴런</h2>
          <hr>

          <p>
            학습 알고리즘이라는 말은 굉장하게 들립니다. 
            그렇다면 뉴럴 네트워크를 위한 학습 알고리즘을 어떻게 설계할 수 있을까요? 
            물제를 풀기 위해 학습에 사용하고 싶은 퍼셉트론 네트워크가 있다고 가정하겠습니다. 
            예를 들어 네트워크에 대한 입력은 손글씨 숫자 이미지를 스캔해서 얻은 가공되지 않은 픽셀 데이터라고 하겠습니다. 
            그리고 우리는 네트워크가 가중치와 편향을 학습하여 네트워크의 출력이 숫자를 올바르게 분류하기를 원합니다. 
            네트워크의 가중치 혹은 편향을 조금씩 바꾼다고 가정하여 어떻게 학습 과정이 일어나는지 살펴보겠습니다. 
            우리가 하고 싶은 것은 가중치의 작은 변화가 네트워크 출력의 작은 변화를 이끈다는 것입니다. 
            잠시 후 알게 되겠지만 이런 속성때문에 학습이 가능합니다. 
            도표로 나타내면 아래와 같습니다.(아래 네트워크는 너무 단순하여 손글씨를 인식하지는 못합니다.) 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz8.png" alt="digits" width="500px">
            <br /><br />
            가중치(또는 편향)가 조금 변할 때 출력도 조금 변한다면 우리는 이 사실을 이용해 가중치와 편향을 수정하면서 원하는 방식으로 네트워크가 동작하도록 만들 수 있습니다. 
            예를 들어, 네트워크가 숫자 "9" 이미지를 숫자 "8"로 잘못 인식한다고 가정해 보겠습니다. 
            그러면 우리는 네트워크가 이미지를 숫자 "9"로 분류하도록 어떻게 가중치와 편향을 조금씩 바꿀지 알아내야 합니다. 
            더 좋은 결과를 얻도록 가중치와 편향을 반복해서 바꾸어 나가야 합니다. 
            이렇게 네트워크는 학습을 진행합니다.
          </p>

          <p>
            문제는 퍼셉트론으로 구성된 네트워크에서는 학습 과정이 일어나지 않습니다. 
            사실 어떤 하나의 퍼셉트론의 가중치 혹은 편향이 조금 변할 때 출력은 0에서 1로 바뀌는 것처럼 완전히 뒤집어 지는 경우가 있습니다. 
            출력이 완전히 뒤바뀌면 네트워크의 나머지 부분도 복잡한 방식으로 완전히 변합니다. 
            그래서 숫자 "9"는 이제 정확히 분류하지만 다른 이미지들의 결과는 통제할 수 없을 정도로 완전히 바뀔 수 있습니다. 
            이러한 이유때문에 얼마만큼 가중치와 편향을 수정해야 네트워크가 원하는 행동에 가까워지는지 알기어렵습니다. 
            아마도 이 문제를 해결하는 다른 현명한 방법이 있을 것입니다. 
            하지만 퍼셉트론 네트워크가 어떻게 학습하는지 명확하게 알기 어렵습니다. 
          </p>

          <p>
            이 문제를 해결하기 위해 시그모이드 뉴런이라는 새로운 형태의 인공 뉴런을 도입하겠습니다. 
            시그모이드 뉴런은 퍼셉트론과 비슷하지만 가중치와 편향이 조금 변할때 출력도 조금 변합니다. 
            이 중요한 사실때문에 시그모이드 뉴런은 학습을 할 수 있습니다. 
          </p>

          <P>
            이제 시그모이드 뉴런을 설명하겠습니다. 
            퍼셉트론을 그렸던 방식처럼 시그모이드 뉴런을 그릴 수 있습니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz9.png" alt="digits" width="300px">
            <br /><br />
            퍼셉트론처럼 시그모이드 뉴런은 입력 $x_1, x_2, \ldots$을 가집니다. 
            대신 입력 값은 $0$ 또는 $1$이 아니라 $0$과 $1$ 사이의 값을 가질 수 있습니다. 
            그래서 예를 들어 $0.638\ldots$ 같은 값은 시그모이드 뉴런의 입력이 될 수 있습니다. 
            또한 퍼셉트론처럼 시그모이드 뉴런도 각 입력에 대한 가중치 $w_1, w_2, \ldots$과 전체 편향 $b$를 가집니다. 
            하지만 출력은 $0$ 또는 $1$이 아닙니다. 
            출력은 $\sigma(w \cdot x+b)$입니다. 
            여기서 $\sigma$는 시그모이드 함수
            <span class="tooltip"><b style="font-size: 20px">*</b>
              <span class="tooltiptext">
                $\sigma$는 로지스틱 함수라고도 부르고, 
                이 뉴런을 로지스틱 뉴런이라 합니다. <br />
                이 용어를 기억해두면 유용합니다. 
                뉴럴 네트워크를 이용하는 많은 사람이 이 용어를 사용하기 때문입니다. <br />
                하지만 이 책에서는 시그모이드라는 용어를 사용하겠습니다.
              </span>
            </span>
            라 부르고 다음과 같이 정의합니다. 
            $$\begin{eqnarray} 
            \sigma(z) \equiv \frac{1}{1+e^{-z}}.
            \tag{3}\end{eqnarray}$$
            조금 더 자세하게 식을 써보겠습니다. 
            입력이 $x_1,x_2,\ldots$, 가중치 $w_1,w_2,\ldots$, 편향 $b$일 때 시그모이드 뉴런의 출력은 다음과 같습니다. 
            $$\begin{eqnarray} 
            \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
            \tag{4}\end{eqnarray}$$
            한 눈에 보면 퍼셉트론과 시그모이드 뉴런의 차이가 커보입니다. 
            수학적 표현에 익숙하지 않으면 이해하기 어렵고 거부감이 있을 수 있습니다. 
            사실 퍼셉트론과 시그모이드 뉴런 사이에는 비슷한 점이 많습니다. 
            수학적으로 이해하는데 장벽이 있는 시그모이드 함수의 수학적 표현은 기술적으로 자세한 부분을 더 많이 알려줍니다. 
          </P>

          <p>
            퍼셉트론 모델과 비슷한 점을 이해하기 위해 $z \equiv w \cdot x + b$은 큰 양수라고 가정해봅시다. 
            그러면 $e^{-z} \approx 0$이 되고 $\sigma(z) \approx 1$이 됩니다. 
            즉, $z = w \cdot x+b$이 아주 큰 양수일 때 시그모이드 뉴런의 출력은 대략 1이 됩니다. 
            퍼셉트론의 경우에도 결과는 같습니다. 
            $z = w \cdot x+b$이 아주 작은 음수라고 가정해봅시다. 
            그러면 $e^{-z} \rightarrow \infty$이고 $\sigma(z) \approx 0$이 됩니다. 
            그래서 $z = w \cdot x+b$이 아주 작은 음수일 때 시그모이드 뉴런의 행동은 대략적으로 퍼셉트론과 비슷합니다. 
            단지 $w \cdot x+b$이 적당한 값을 가질 때만 퍼셉트론 모델과의 차이를 보입니다. 
          </p>

          <p>
            $\sigma$의 수학적 표현은 어떤가요? 
            우리는 그것을 어떻게 이해면 될까요? 
            사실 $\sigma$의 수학적 표현 자체는 크게 중요하지 않습니다. 
            중요한 것은 함수를 그래프를 그렸을 때의 모양입니다. 
            아래 그래프가 있습니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/graph-ch1-01.png" alt="digits" width="500px">
            <br /><br />
            아래의 그래프는 계단 함수의 그래프입니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/graph-ch1-02.png" alt="digits" width="500px">
            <br /><br />
            $\sigma$가 계산 함수라면 시그모이드 뉴런은 $w\cdot x+b$이 양수냐 음수냐
            <span class="tooltip"><b style="font-size: 20px">*</b>
              <span class="tooltiptext">
                사실 $w \cdot x +b = 0$일 때 퍼셉트론의 출력은 $0$이고, 계단 함수의 출력은 $1$입니다. <br />
                그래서 엄밀히 따지자면 계단 함수를 수정할 필요가 있습니다. <br />
                하지만 아이디어를 얻을 수 있습니다. 
              </span>
            </span>
            에 따라 출력이 1 또는 0이 되므로 퍼셉트론이 될 것입니다. 
            실제 $\sigma$ 함수를 사용하여 우리는 위에서 살펴본 퍼셉트론을 얻을 수 있습니다. 
            $\sigma$ 함수의 수학적 표현보다 부드러운 곡선 형태가 정말 중요합니다. 
            $\sigma$ 함수의 부드러운 곡선 형태가 의미하는 것은 뉴런에서 가중치의 아주 작은 변화 $\Delta w_j$와 편향의 아주 작은 변화 $\Delta b$에 의해 출력의 아주 작은 변화 $\Delta \mbox{output}$을 얻는다는 것입니다. 
            사실 미분을 이용하면 $\Delta \mbox{output}$을 다음과 같이 쓸 수 있습니다. 
            $$\begin{eqnarray} 
            \Delta \mbox{output} \approx \sum_j \frac{\partial \, \mbox{output}}{\partial w_j}
            \Delta w_j + \frac{\partial \, \mbox{output}}{\partial b} \Delta b,
            \tag{5}\end{eqnarray}$$
            여기서 합은 모든 가중치 $w_j$에 대한 것이고, 
            $\partial \, \mbox{output} / \partial w_j$과 $\partial \, \mbox{output} /\partial b$은 
            각각 $w_j$과 $b$에 대한 출력의 편미분을 의미합니다. 
            편미분을 모르더라도 괜찮습니다. 
            편미분 때문에 위의 식이 복잡해 보이지만 사실 말하고자 하는 것은 아주 간단합니다. 
            $\Delta \mbox{output}$은 가중치와 편향에서의 변화 $\Delta w_j$와 $\Delta b$에 대한 선형 함수입니다. 
            이러한 선형성 때문에 출력에서 원하는 아주 작은 변화를 만들기 위해 가중치와 편향에서 아주 작은 변화를 고르는 것이 쉽습니다. 
            그래서 시그모이드 뉴런이 퍼셉트론과 같은 행동을 보이지만 시그모이드 뉴런은 출력을 바꾸기 위해 가중치와 편향을 얼마만큼 바꿔야 하는지 알기 쉽습니다. 
          </p>

          <p>
            $\sigma$ 함수의 수학적 표현보다 그래프 모양이 중요하다면 방정식
            <span class="tooltip"><b>(3)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \sigma(z) \equiv \frac{1}{1+e^{-z}} \nonumber\end{eqnarray}$$
              </span>
            </span>
            과 같은 $\sigma$의 수학적 표현을 사용하는 이유는 무엇일까요? 
            사실 책의 뒷 부분에서 다른 활성화 함수 $f(\cdot)$에 대한 출력이 $f(w \cdot x + b)$인 뉴런을 언급할 것입니다. 
            다른 활성화 함수를 사용할 때 주된 변화는 방정식
            <span class="tooltip"><b>(5)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta \mbox{output} \approx \sum_j \frac{\partial \, \mbox{output}}{\partial w_j}
                \Delta w_j + \frac{\partial \, \mbox{output}}{\partial b} \Delta b \nonumber\end{eqnarray}$$
              </span>
            </span>
            에서 나타나는 편미분 값의 변화입니다. 
            지수함수의 미분은 몇몇 특성을 지니므로 나중에 편미분을 계산할 때  $\sigma$를 사용하면 계산을 간단히 할 수 있습니다. 
            어쨋든 $\sigma$는 뉴럴 네트워크에서 흔하게 사용되고, 이 책의 대부분에서 사용되는 활성화 함수입니다. 
          </p>

          <p>
            시그모이드 뉴런의 출력은 어떻게 해석하면 될까요? 
            시그모이드 뉴런의 출력은 단지 0 또는 1이 아니라는 점이 분명 퍼셉트론과 시그모이드 뉴런의 큰 차이입니다. 
            시그모이드 뉴런의 출력은 $0$과 $1$사이의 어떤 실수도 될 수 있습니다. 
            따라서 $0.173\ldots$과 $0.689\ldots$같은 값도 출력이 될 수 있습니다. 
            예를 들어 시그모이드 뉴런의 출력을 이용해서 뉴럴 네트워크의 입력 이미지 픽셀의 평균 명암도를 나타낼 수 있습니다. 
            하지만 골칫거리일 수 있습니다. 
            네트워크의 출력이 입력 이미지가 "9"인지 아닌지를 나타내고 싶다고 생각해봅시다. 
            분명히 퍼셉트론처럼 출력이 $0$ 또는 $1$이면 굉장히 쉽습니다. 
            하지만 실제로 이를 다루기 위해서는 규칙을 정해야 합니다. 
            예를 들어 출력이 $0.5$ 이상이면 "9"로 해석하고, 출력이 $0.5$ 보다 작으면 "9가 아니다"라고 해석합니다. 
            책에서는 혼란을 주지 않기 위해 이런 규칙을 명확히 정의해 놓았습니다. 
          </p>

          <br />
          <h2>예제</h2>

          <p>
            <ul>
              <li>시그모이드 뉴런 파트 1</li>
              <p>
                블라블라
              </p>
              <li>시그모이드 뉴런 파트 2</li>
            </ul>
          </p>

          <br />
          <h2>뉴럴 네트워크의 구조</h2>
          <hr>

          <p>
            이번 절에서는 손 글씨 숫자 분류 작업 성능이 좋은 뉴럴 네트워크를 소개하겠습니다.  
            먼저 네트워크의 서로 다른 부분을 부르는 용어에 대해 설명하겠습니다. 
            아래와 같은 네트워크가 있다고 가정해봅시다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz10.png" alt="digits" width="400px">
            <br /><br />
            앞서 살펴본 것 처럼 네트워크에서 가장 왼쪽에 있는 층은 입력 층이라 부릅니다. 
            입력 층에 있는 뉴런은 입력 뉴런이라 부릅니다. 
            가장 왼쪽에 있는 출력 층은 출력 뉴런을 가지고 있습니다. 
            위의 예에서는 하나의 출력 뉴런을 가지고 있습니다. 
            가운데 있는 층은 은닉 층이라 부릅니다. 
            은닉 층에 있는 뉴런은 입력도 아니고 출력도 아니기 때문이 이런 이름이 붙었습니다. 
            "은닉"이라는 용어가 이상하게 들리지도 모릅니다. 
            저는 처음 이 용어를 들었을 때 어떤 심오한 철학이나 수학적 중요성이 있을 것이라 생각했습니다. 
            하지만 "입력도 아니고 출력도 아니다"라는 의미 이외에 다른 뜻은 없습니다. 
            위의 네트워크는 하나의 은닉 층을 가지고 있지만 어떤 네트워크는 다수의 은닉 층을 가집니다. 
            예를 들어 아래의 네 개 층으로 구성된 네트워크는 두 개의 은닉층을 가집니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz11.png" alt="digits" width="700px">
            <br /><br />
            다소 헷갈릴 수 있지만 역사적인 이유 때문에 다층 네트워크를 퍼셉트론이 아닌 시그모이드 뉴런으로 이루어졌다 할지라도 종종 다층 퍼셉트론이라 부르기도 합니다. 
            이 책에서는 다층 퍼셉트론이라는 말을 쓰지 않을 것입니다. 
            헷갈릴 수 있는 용어라고 생각하기 때문입니다. 
            하지만 이런 용어가 있다는 것을 알아두세요. 
          </p>

          <p>
            네트워크에서 입력층과 출력층의 설계는 간단합니다. 
            예를 들어 손글씨 이미지가 "9"인지 아니지 결정하고 싶다고 합시다. 
            네트워크를 설계하는 자연스러운 방법은 이미지 픽셀의 명암을 입력 뉴런으로 인코딩하는 것입니다. 
            이미지가 $64 \times 64$ 그레이스케일 이미지라면 $0$에서 $1$ 사이 값을 명암을 가지는 입력 뉴런 $4,096 = 64 \times 64$개를 가지면 됩니다. 
            출력층은 입력 이미지가 "9"가 아니면 $0.5$보다 작은 값을 출력으로 하고, "9"가 맞으면 $0.5$보다 큰 값을 출력으로 하는 하나의 뉴런을 가지면 됩니다. 
          </p>

          <p>
            뉴럴 네트워크의 입력과 출력층의 설계는 간단하지만 은닉 층의 설계는 상당한 기술이 필요합니다. 
            특히 은닉 층의 설계 과정을 간단한 규칙으로 설명하는 것은 불가능합니다. 
            대신 뉴럴 네트워크 연구자들은 은닉 층에 대해 많은 경험에서 우러나온 설계 방법을 개발했습니다. 
            이를 통해 뉴럴 네트워크에서 원하는 행동을 얻을 수 있습니다. 
            예를 들어 이런 방법을 통해 은닉 층 개수와 네트워크를 학습시키는 시간 사이의 균형을 유지할 수 있습니다. 
            이 책의 뒷부분에서 이런 설계 방식에 대해 살펴보겠습니다. 
          </p>

          <p>
            지금까지 한 층에서 나온 출력이 다른 층의 입력으로 사용되는 뉴럴 네트워크에 대해 살펴보았습니다. 
            이런 네트워크를 피드포워드 뉴럴 네트워크라고 부릅니다. 
            이는 네트워크에 루프가 없다는 것을 의미합니다. 
            정보는 항상 앞으로 이동하고 뒤로 돌아오는 피드백 과정은 없습니다. 
            네트워크에 루프가 있다면 $\sigma$ 함수의 입력이 출력에 따라 바뀌는 상황을 마주합니다. 
            이는 이해하기 어려운 일이기 때문에 루프를 제외했습니다.
          </p>

          <p>
            하지만 피드백 루프가 존재하는 인공 뉴럴 네트워크 모델이 있습니다. 
            이런 모델을 <a href="https://ko.wikipedia.org/wiki/%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D">리커런트 뉴럴 네트워크</a>라고 합니다. 
            이 모델은 휴지 상태가 되기 전에 일정 시간동안 활동 상태가 지속되는 뉴런을 아이디어로 하고 있습니다. 
            뉴런이 활동전위가 되면 다른 뉴런을 자극하여 약간의 시간이 흐른 뒤 활동전위가 됩니다. 
            그리고 시간이 지나면서 연속적으로 다른 뉴런들도 활동전위가 됩니다. 
            루프는 이런 모델에서 아무 문제가 없습니다. 
            뉴런의 출력이 즉시 입력에 영향을 주는 것이 아니라 약간의 시간이 지난 뒤 영향을 주기 때문입니다.  
          </p>

          <p>
            리커런트 뉴럴 네트워크는 피드 포워드 네트워크보다 영향력이 크지 않습니다. 
            현재까지는 리커런트 뉴럴 네트워크의 학습알고리즘이 강력하지 않기 때문입니다. 
            하지만 리커런트 뉴럴 네트워크는 매우 흥미롭습니다. 
            리커런트 뉴럴 네트워크는 피드 포워드 네트워크보다 인간 두뇌 동작방식과 유사합니다. 
            그리고 피드 포워드 네트워크에서는 풀기 어려운 문제가 리커런트 뉴럴 네트워크가 풀 수 있습니다. 
            하지만 범위를 제한해서 이 책에서는 더 많이 사용되는 피드 포워드 네트워크에 집중하겠습니다. 
          </p>

          <br />
          <h2>손글씨 숫자를 분류하는 간단한 뉴럴 네트워크</h2>
          <hr>

          <p>
            뉴럴 네트워크를 정의했으니 다시 손글씨 인식 문제로 돌아가 봅시다. 
            손글씨 숫자 인식 문제를 두 개의 문제로 나눠 볼 수 있습니다. 
            먼저 여러 개의 숫자를 포함하는 이미지를 하나의 숫자를 포함하는 별개의 이미지로 나눕니다. 
            예를 들어 아래의 이미지를 6개의 이미지로 나눕니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/digits.png" alt="digits" width="300px">
            <br /><br />

            <br /><br />
            <img class="contentimg" src="./images/chapter1/digits_separate.png" alt="digits" width="400px">
            <br /><br />
            인간은 이 세그멘테이션 문제를 쉽게 풀 수 있지만 컴퓨터 프로그램이 풀기에는 어렵습니다. 
            이미지를 구분 한 뒤 프로그램은 각 숫자를 분류합니다. 
            예를 들어 위에서 프로그램이 첫 번째 숫자를 인식하면 5입니다.
            <br /><br />
            <img class="contentimg" src="./images/chapter1/mnist_first_digit.png" alt="digits" width="50px">
            <br /><br />
          </p>

          <p>
            이제 각 숫자를 분류하는 프로그램을 작성하는 법을 살펴보겠습니다. 
            일단 개별 숫자를 분류하는 좋은 방법이 있다면 분할 문제는 그렇게 풀기 어려운 문제는 아닙니다. 
            분할 문제는 푸는 방법은 여러가지가 있습니다. 
            한 가지 방법은 이미지를 분할하는 서로 다른 많은 시도를 하고 개별 숫자 분류기를 이용하여 각 분할에 대해 점수를 매기는 것입니다. 
            모든 분할에 대해 숫자 분류기를 신뢰할 수 있으면 분할 시도는 높은 점수를 받습니다. 
            분류기가 하나 또는 그 보다 많은 분할에서 문제를 가지면 낮은 점수를 받습니다. 
            분류기가 어딘가에서 문제를 가지면 분할이 잘못 선택되었기에 문제가 발생한다는 아이디어입니다. 
            이 아이디어와 다른 변형들이 사용되어 분할 문제를 잘 풀 수 있습니다. 
            그래서 분할 문제가 아닌 더 흥미롭고 어려운 문제인 손글씨 숫자 인식 문제를 풀 수 있는 뉴럴 네트워크 개발에 집중할 것입니다.  
          </p>

          <p>
            각 숫자를 인식하기 위해 삼중층 뉴럴 네트워크를 사용하겠습니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz12.png" alt="digits" width="600px">
            <br /><br />
            뉴럴 네트워크의 입력층은 입력 픽셀 값을 인코딩하는 뉴런을 포함한다. 
            다음 절에서 살펴보겠지만 뉴럴 네트워크의 학습 데이터는 손글씨를 스캔한 28x28 픽셀 이미지로 구성됩니다. 
            그리고 입력층은 $784 = 28 \times 28$개 뉴런을 포함합니다. 
            간단하게 그리기 위해 위의 다이어그램에서는 784개 뉴런 중 일부만 그렸습니다. 
            입력 픽셀은 그레이스케일이고 $0.0$의 값은 흰색을 $1.0$은 검은색을 나타냅니다. 
            그리고 이 사이값은 점점더 어두워지는 흑색을 나타냅니다. 
          </p>

          <p>
            뉴럴 네트워크의 두 번째 층은 은닉층입니다. 
            은닉층에 있는 뉴런의 개수를 $n$이라 하고 $n$의 수를 달리하며 실험하겠습니다. 
            예시 그림에서 은닉층은 $n=15$개의 뉴런만 포함하고 있습니다. 
          </p>

          <p>
            뉴럴 네트워크의 출력층은 10개의 뉴런을 포함합니다. 
            첫 번째 뉴런이 활성화되어 출력으로 1을 가진다면 뉴럴 네트워크가 숫자를 0으로 분류했다는 것을 의미합니다. 
            두 번째 뉴런이 활성화되면 뉴럴 네트워크가 숫자를 1로 분류했다는 의미입니다. 
            세 번째 뉴런, 그 이후의 뉴런에도 마찬가지로 적용하면 됩니다. 
            조금 더 정확하게 출력 뉴런을 $0$에서 $9$까지 번호를 매기고 어느 뉴런의 활성 값이 가장 높은지 알아냅니다. 
            예를 들어 $6$번 뉴런이 활성화된다면 신경망은 입력 숫자가 $6$이라고 판단합니다. 
            다른 출력 뉴런에 대해서도 마찬가지입니다. 
          </p>

          <p>
            왜 $10$개의 뉴런을 사용하는지 궁금할 수 있습니다. 
            무엇보다도 신경망의 목표는 숫자 $0, 1, 2, \ldots, 9$에 대응하는 입력 이미지를 판별하는 것입니다. 
            겉보기에는 뉴런의 출력이 $0$ 또는 $1$인지에 따라 이진 값을 가지도록 하는 4개의 출력뉴런을 사용하면 될 것 같습니다. 
            4개의 뉴런은 $2^4 = 16$으로 10개의 가능한 입력 숫자 값을 가지므로 답을 인코딩하기에 충분합니다. 
            하지만 왜 이 신경망에서 $10$개의 뉴런을 사용할까요? 
            비효율적이지 않나요? 
            타당한 이유는 경험적인 바탕에 있습니다. 
            두 가지 신경망을 설계해서 실험할 수 있고, 이 특별한 문제에 대해서는 4개의 출력 뉴런을 가지는 신경망보다 10개의 출력 뉴런을 가지는 신경망이 숫자 인식을 더 잘 학습합니다. 
            하지만 여전히 왜 10개의 출력 뉴런을 가지는 것이 더 잘 동작하는지 의문이 남아있습니다. 
            4개 출력을 인코딩하는 대신에 10개 출력을 인코딩하는 것을 미리 알 수 있는 방법은 있을까요? 
          </p>

          <p>
            우리가 이것을 왜 하는지 이해하하는데 신경망은 첫번째 원칙에서 무엇을 하는지 생각하는 것이 도움을 줄 수 있습니다. 
            먼저 10개의 출력 뉴런을 사용하는 경우를 생각해봅시다. 
            첫 번째 출력 뉴런을 보면 숫자가 0인지 아닌지 결정하기 위한 뉴런입니다. 
            은닉층의 증거를 가늠하여 이를 결정합니다. 
            은닉층 뉴런은 무엇을 할까요? 
            은닉층에 있는 첫 번째 뉴런이 아래와 같은 이미지가 있는지 없는지 판단한다고 가정해봅시다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/mnist_top_left_feature.png" alt="digits" width="130px">
            <br /><br />
            이미지와 겹치는 입력 픽셀은 가중치를 많이 두고 다른 입력은 가중치를 적게 두어 이를 판변할 수 있습니다. 
            비슷한 방법으로 은닉층의 두 번째, 세 번째, 네번째 뉴런이 아래의 이미지가 있는지 판단한다고 가정해봅시다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/mnist_other_features.png" alt="digits" width="450px">
            <br /><br />
            추측하다시피 위 네 개의 이미지는 처음에 보았던 숫자들 중 숫자 $0$ 이미지를 만듭니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/mnist_complete_zero.png" alt="digits" width="130px">
            <br /><br />
            그래서 은닉층에 있는 네 개의 뉴런이 모두 활성화되면 숫자가 $0$이라고 결론지을 수 있습니다. 
            물론 이미지가 $0$이라고 결론지을 수 있는 유일한 증거는 아닙니다. 
            다른 많은 방법으로도 $0$이라는 결정을 내릴 수 있습니다. 
            (가령 위 이미지의 번역이나 약간의 왜곡을 통해 알 수 있습니다.) 
            하지만 적어도 이 경우에는 입력이 $0$이라고 결론지을 수 있습니다. 
          </p>

          <p>
            신경망이 이런 방법으로 기능한다고 가정하면 4개의 출력보다 10개의 출력 뉴런을 가지는게 왜 좋은지 설명할 수 있습니다. 
            네 개의 출력을 가진다면 첫 번째 뉴런은 숫자 비트 중 어느 것이 가장 중요한지 결정하려 할 것입니다. 
            숫자에서 가장 중요한 비트를 위에서 본 간단한 모양과 관련짓는 쉬운 방법은 없습니다. 
            숫자의 모양과 출력에서 중요한 비트 사이에 밀접한 관련이 있다는 역사적 사실을 상상하기는 어렵습니다. 
          </p>

          <p>
            모두 말했듯이 이것은 경험적 발견입니다. 
            삼중층 신경망이 간단한 모양을 은닉층에 있는 뉴런이 가지하면서 제가 설명한 방법으로 동작해야한다는 것은 아닙니다. 
            아마도 더 현명한 학습알고리즘은 가중치 값을 찾아 단지 4개의 출력 뉴런만을 사용하는 방법을 알려줄 것입니다. 
            하지만 제가 설명한 경험적 발견 법칙은 잘 동작하기 때문에 좋은 신경망 구조를 설계하는데 많은 시간을 아낄 수 있습니다. 
          </p>

          <br />
          <h2>예제</h2>
          <hr>

          <p>
            <ul>
              <li>
                위에서 설명한 삼중층에 추가적인 층을 더해 숫자의 비트 표현을 결정하는 방법이 있습니다. 
                추가적인 층은 이전 층의 출력을 이진법으로 변환합니다. 
                아래의 그림을 보세요. 
                새로운 출력 층의 가중치와 편향을 찾으세요. 
                처음 세개 층의 뉴런은 다음과 같은 설명을 가진다고 가정합니다. 
                세 번째 층의 올바른 출력은 적어도 $0.99$ 이상 활성화되고 
                올바르지 않은 출력은 $0.01$ 이하 활성화됩니다. 
              </li>
            </ul>
            <br /><br />
            <img class="contentimg" src="./images/chapter1/tikz13.png" alt="digits" width="700px">
            <br /><br />
          </p>

          <br />
          <h2>경사 하강으로 학습하기</h2>
          <hr>

          <p>
            이제 신경망을 설계하였으니 신경망이 숫자를 인식하기 위해 어떻게 학습을 할까요? 
            먼저 필요한 것은 학습하기 위한 데이터 셋입니다. 
            이 데이터 셋은 학습 데이터 셋이라고도 부릅니다. 
            여기서 MNIST 데이터 셋을 사용하겠습니다. 
            MNIST 데이터 셋은 수만개의 스캔한 손글씨 숫자를 포함하고 있고 숫자의 올바른 분류를 가지고 있습니다. 
            MNIST는 NIST(미국표준기술연구소)가 수집한 두 데이터 셋의 수정된 부분집합이라는 의미입니다. 
            아래 MNIST 데이터 셋 중 일부를 가져왔습니다.
            <br /><br />
            <img class="contentimg" src="./images/chapter1/digits_separate.png" alt="digits" width="500px">
            <br /><br />
            알다시피 이 숫자는 사실 이 장의 처음 부분에 보여주었던 것과 같습니다. 
            물론 신경망을 테스트할 때 학습 데이터 셋이 아닌 이미지를 인식하도록 합니다. 
          </p>

          <p>
            MNIST 데이터 셋은 두 부분으로 나뉩니다. 
            첫 번째 부분은 학습 데이터로 사용되는 60,000개의 이미지를 포함합니다. 
            이 이미지는 250명의 사람들의 손글씨를 스캔한 것입니다. 
            이들 중 절반은 미국 통계국 직원이며 나머지 절반은 고등학생입니다. 
            이미지는 흑백이며 28x28 픽셀 크기입니다. 
            MNIST 데이터 셋의 두 번째 부분은 테스트 데이터로 사용되는 10,000개의 이미지입니다. 
            이 이미지도 28x28 크기의 흑백 이미지입니다. 
            우리는 테스트 데이터를 사용하여 신경망이 숫자 인식을 하기위해 학습을 얼마나 잘 하였는지 평가합니다. 
            좋은 테스트 성능을 만들기 위해 테스트 데이터는 기존 학습 데이터와 다른 250명의 사람들에서 가져왔습니다. 
            (마찬가지로 250명 중 절반은 미국 통계국 직원이고 나머지 절반은 고등학생입니다.) 
            이는 신경망이 학습하는 동안 보지 못한 데이터를 인식할 수 있다는 신뢰도를 높여줍니다.  
          </p>

          <p>
            $x$를 학습 데이터 입력이라고 해봅시다. 
            각 학습 데이터 입력 $x$를 28 $\times 28 = 784$ 차원 벡터로 생각하면 편리합니다. 
            벡터의 각 성분은 이미지에서 하나의 픽셀에 대한 흑백 값을 나타냅니다. 
            대응하는 원하는 출력을 $y = y(x)$이라 표시합니다. 
            여기서 $y$는 $10$ 차원 벡터입니다. 
            예를 들어 학습 이미지 $x$가 $6$을 나타낸다면 $y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$은 신경망으로 부터 얻을 수 있는 출력입니다. 
            여기서 $T$는 전치행렬이며 행 벡터를 열 벡터로 바꿉니다. 
          </p>

          <p>
            우리가 하고자 하는 바는 알고리즘이 가중치와 편향을 찾아 신경망의 결과가 모든 학습 데이터 입력 $x$에 대해 $y(x)$에 근사하는 것이다. 
            이 목표에 얼마나 잘 도달했는지 수량화하기위해 비용함수
            <span class="tooltip"><b>*</b>
              <span class="tooltiptext">
                비용함수는 손실함수 또는 목적함수라고도 한다. <br />
                이 책에서는 비용함수라는 용어를 사용하지만  <br />
                신경망에 대한 연구 논문에서 다른 용어들이 사용되므로 알아둘 필요가 있다. <br />
              </span>
            </span>
            를 정의한다. 
            $$\begin{eqnarray}  C(w,b) \equiv
            \frac{1}{2n} \sum_x \| y(x) - a\|^2.
            \tag{6}\end{eqnarray}$$
            여기서 $w$는 신경망에서 모든 가중치를 의미하고 $b$는 모든 편향, $n$은 학습 데이터 입력의 수를 의미한다. 
            $a$는 입력이 $x$일 때 신경망의 출력 벡터이며, 합은 모든 학습 데이터 입력 $x$에 대한 값이다. 
            물론 출력 $a$는 $x, w, b$에 따라 달라지며 표기를 간단히 하기위해 이런 상관성을 나타내지 않았다. 
            $\| v \|$은 벡터 $v$의 길이를 나타낸다. 
            여기서 $C$를 이차 비용함수라 부르겠다. 
            이차 비용함수는 평균제곱오차(mean squared error, MSE)라고도 한다. 
            이차 비용함수의 형태를 살펴보면, 합의 각 항은 음수가 아니므로 $C(w,b)$은 음수가 아니다. 
            게다가 $y(x)$가 모든 학습 데이터 입력 $x$에 대한 출력 $a$에 근사할 때 비용 $C(w,b)$은 작은 값 $C(w,b) \approx 0$이 된다. 
            그래서 학습 알고리즘이 $C(w,b) \approx 0$가 되는 가중치와 편향을 찾을 수 있다면 학습 알고리즘은 좋은 성능을 낼 수 있다. 
            반대로 $C(w,b)$이 매우 클 때는 많은 수의 입력에 대한 $y(x)$의 값이 출력 $a$에 근사하지 않다는 것을 의미하며 학습 알고리즘의 성능은 떨어진다. 
            그래서 학습 알고리즘의 목표는 가중치와 편향의 함수인 비용 $C(w,b)$을 최소화하는 것이다. 
            즉, 가능한 비용을 작게 하는 가중치와 편향의 집합을 찾고자 한다. 
            이를 위해 경사 하강법이라 알려진 알고리즘을 이용할 것이다. 
          </p>

          <p>
            왜 이차 비용함수를 도입할까? 
            무엇보다 신경망이 올바르게 분류하는 이미지의 수가 중요하지 않은가? 
            왜 올바르게 분류되는 이미지 수를 직접 최대화하지 않고 이차 비용함수와 같은 다른 방법을 사용하는 걸까? 
            올바르게 분류되는 이미지의 수는 신경망의 가중치와 편향에 대한 부드러운 모양의 함수가 아닌 것이 문제이다. 
            대부분의 경우 가중치와 편향에 약간의 변화를 가할 때 올바르게 분류하는 학습 데이터 이미지의 수의 변화는 거의 없다. 
            이는 성능을 향상시키기 위해 가중치와 편향을 얼마나 바꿔야하는지 알아내기 어렵다. 
            대신 이차 비용함수같이 부드러운 비용함수를 사용하면 비용에서 성능을 향상시키기 위해 가중치와 편향을 얼마나 바꾸어야하는지 알기 쉽다. 
            이러한 이유로 이차 비용함수를 최소화하려 한다. 
            그리고 그 뒤에 분류의 정확도를 측정할 것이다.  
          </p>

          <p>
            부드러운 비용함수를 사용하더라도 왜 방정식 (6)과 같은 이차함수를 사용하는지 궁금할 것이다. 
            임의로 선택한 것은 아닐까? 
            다른 비용함수를 선택한다면 완전히 다른 가중치와 편향을 가질까? 
            이는 타당한 의심이다. 
            그리고 뒤에서 다시 한번 비용함수를 살펴보고 약간의 수정을 해볼 것이다. 
            하지만 방정식 (6)과 같은 이차 비용함수를 이용하여 신경망 학습의 기본을 잘 이해할 수 있기 때문에 당분간 이에 집중할 것이다. 
          </p>

          <p>
            간략하게 다시 말하면, 목표는 신경망을 학습시켜 이차 비용함수 $C(w, b)$를 최소화하는 가중치와 편향을 찾는 것이다. 
            이는 우량조건문제(well-posed problem)이지만 가중치 $w$와 편향 $b$의 해석, 백그라운드에 숨어있는 $\sigma$함수, 신경망 구조의 선택, MNIST 등과 같은 많은 주의 분산 구조가 있습니다. 
            대부분의 구조를 무시하고 최소화에만 집중하면 많은 부분을 이해할 수 있습니다. 
            그래서 비용함수의 구체적인 형태와 신경망의 연결 등에 대해서 당분간 신경쓰지 않도록 하겠습니다. 
            대신 다변수 함수가 주어지고 이 함수를 최소화할 것입니다. 
            최소화 문제를 풀 수 있는 경사 하강법이라 불리는 기술을 살펴보겠습니다. 
            그 뒤 신경망에 대해 최소화하려는 특정 함수로 돌아오겠습니다. 
          </p>

          <p>
            함수 $C(v)$를 최소화한다고 가정합시다. 
            이는 다변수 $v = v_1, v_2, \ldots$에 대한 실수값 함수입니다. 
            $w$와 $b$를 $v$로 치환하여 어떤 함수도 될 수 있다는 점을 강조하겠습니다. 
            더이상 신경망의 관점에서 생각하지 않습니다. 
            $C(v)$를 최소화하기 위해 $C$를 두개의 변수 $v_1$과 $v_2$에 대한 함수로 생각하면 쉽습니다. 
            <br /><br />
            <img class="contentimg" src="./images/chapter1/valley.png" alt="digits" width="500px">
            <br /><br />
            $C$가 최솟값이 되는 지점을 찾을 것입니다. 
            물론 위의 함수 그래프를 눈으로 보고 최솟값을 찾을 수 있습니다. 
            이는 제가 그래프를 단순하게 그렸기 때문입니다. 
            일반적인 함수 $C$는 많은 수의 변수를 가진 복잡한 함수일 수 있으며 눈으로 최솟값을 찾기 어려울 것입니다. 
          </p>

          <p>
            문제를 공략하는 한 방법은 미분을 사용하여 최솟값을 찾는 것입니다. 
            도함수를 구해 $C$의 극값을 찾을 수 있습니다. 
            운 좋게 함수 $C$가 하나 또는 적은 수의 변수에 대한 함수이면 이는 잘 동작할 것입니다. 
            하지만 훨씬 많은 변수에 대한 함수라면 어려울 것입니다. 
            신경망의 경우 훨씬 더 많은 변수를 다룹니다. 
            가장 큰 신경망은 복잡한 방법으로 수억개의 가중치와 편향에 의존하는 비용함수를 가집니다. 
            미분을 사용하여 이를 최적화하기에는 역부족입니다. 
          </p>

          <p>
            (
              $C$를 두 변수에 대한 함수라 생각해 통찰력을 얻은 뒤, 
              두 문단 뒤에 입장을 바꿔 "두 변수 이상일 경우 함수는 어떨까요?"라고 물을 것입니다. 
              유감스럽게 생각합니다. 
              $C$를 두 변수에 대한 함수로 생각하는 것은 정말 도움이 될 것입니다. 
              이런 이해가 무너지는 일이 발생합니다. 
              지난 두 문단에서는 이러한 붕괴에대해 다루었습니다.
              수학에 대한 좋은 생각은 다수의 직관적인 이해를 오가는 것을 포함합니다. 
              적절한 곳에 각 이해를 사용하는 것이 중요합니다. 
            )
          </p>

          <p>
            결국 미분은 동작하지 않습니다. 
            다행스럽게도 잘 동작하는 알고리즘을 제시하는 아름다운 비유가 있습니다. 
            우리의 함수를 계곡이라고 생각해봅시다. 
            그리고 공이 계곡 경사를 따라 굴러 내려간다고 상상해봅시다. 
            일상적인 경험으로 미루어볼때 공은 결국 계곡의 아래로 내려갈 것입니다. 
            이 아이디어를 이용해서 함수의 최솟값을 찾는 방법을 얻을 수 있슬 것입니다. 
            상상의 공이 시작하는 지점을 무작위로 고르고 계곡 바닥을 향해 굴러내려가는 공의 움직임을 시뮬레이션해봅시다. 
            이 시뮬레이션을 $C$의 도함수를 계산하여 간단하게 해볼 수 있습니다. 
            (아마 이차 도함수를 사용해야할 것입니다.)
            이 도함수는 계곡의 국지적 모양에 대해 알아야할 모든것을 알려줍니다. 
            따라서 공이 어떻게 움직이는지 알 수 있습니다.
          </p>

          <p>
            방금한 설명에서 공에 대해 마찰력과 중력 등을 고려햐여 뉴턴의 운동방정식을 쓸 것이라고 생각할 수 있다. 
            사실 공의 움직임을 그렇게 심오하게 살펴보지는 않을 것이다. 
            단지 $C$를 최소화하는 알고리즘을 만드는 것이지 물리 법칙을 이용해 정확한 시뮬레이션을 하려는 것은 아니다. 
            공의 관점으로 사고를 제한하지 않고 상상을 실험한다. 
            그래서 물리의 사소한 부분에 파고들지 말고 스스로에게 간단하게 물어보자. 
            하루동안 신(god)이 된다면 공이 어떻게 움직여야하는지 자신의 물리 법칙을 만들어 공이 계곡의 바닥으로 항상 굴러가게 만들수 있을까?  
          </p>

          <p>
            질문을 다시 써보자. 
            공이 $v_1$ 방향으로 $\Delta v_1$ 만큼 움직이고 $v_2$ 방향으로 $\Delta v_2$ 만큼 움직일때 어떤 일이 일어나는지 생각해보자. 
            미분을 이용해 $C$의 변화를 다음과 같이 쓸 수 있다. 
            $$\begin{eqnarray} 
            \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
            \frac{\partial C}{\partial v_2} \Delta v_2.
            \tag{7}\end{eqnarray}$$
            $\Delta C$를 음수로 만드는 $\Delta v_1$과 $\Delta v_2$를 선택하는 방법을 찾고자 한다.  
            즉 공이 계곡으로 굴러 내려가는 변수를 선택할 것이다. 
            $\Delta v$를 $v$에 관해 변화하는 벡터 $\Delta v \equiv (\Delta v_1, \Delta v_2)^T$로 정의한다. 
            여기서 $T$는 전치 행렬 연산이며 행벡터를 열벡터로 바꾼다. 
            $C$의 경사를 편미분의 벡터 $\left(\frac{\partial C}{\partial v_1}, \frac{\partial C}{\partial v_2}\right)^T$로 정의한다. 
            경사 벡터를 $\nabla C$로 표기한다. 
            $$\begin{eqnarray} 
            \nabla C \equiv \left( \frac{\partial C}{\partial v_1}, 
            \frac{\partial C}{\partial v_2} \right)^T.
            \tag{8}\end{eqnarray}$$
            잠시뒤 변화량 $\Delta C$을 $\Delta v$와 경사 $\nabla C$에 관해 쓸 것이다. 
            하지만 그 전에 경사에 대한 이해에 어려움을 껵는 사람들에 대해 몇가지를 분명히하고자 한다. 
            $\nabla C$를 처음 본 사람들은 어떻게 $\nabla$ 기호를 이해해야하는지 궁금해한다. 
            $\nabla$은 정확히 무엇을 의미할까?
            사실 $\nabla C$을 하나의 수학적 객체로 이해하여 위에서 정의한 벡터로 생각해도 좋다. 
            이는 두 가지 기호를 사용하여 표시될 수 있다. 
            이 관점에서 $\nabla$은 "$\nabla$은 경사 벡터야."라고 말하는 표기에 불과하다. 
            $\nabla$을 독립적인 수학적 개체로 보는 심화된 관점이 있지만 여기서는 불필요하다. 
          </p>

          <p>
            이 정의에 의해 $\Delta C$에 관한 식
            <span class="tooltip"><b>(7)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
                \frac{\partial C}{\partial v_2} \Delta v_2 \nonumber\end{eqnarray}$$
              </span>
            </span>
            은 다음과 같이 쓸 수 있다. 
            $$\begin{eqnarray} 
            \Delta C \approx \nabla C \cdot \Delta v.
            \tag{9}\end{eqnarray}$$
            $\nabla C$이 왜 경사 벡터라 불리는지 이 식을 통해 알 수 있다. 
            경사라 불리는 것이 하는 것처럼 $\nabla C$는 $C$에 관한 변화를 $v$에 관한 변화와 연관짓는다. 
            이 식에 대해 흥미로운 점은 $\Delta C$를 음수로 만드는 $\Delta v$를 어떻게 선택할지 보여준다. 
            특히 다음을 가정하자. 
            $$\begin{eqnarray} 
            \Delta v = -\eta \nabla C,
            \tag{10}\end{eqnarray}$$
            여기서 $\eta$는 학습율이라 알려진 작은 양수 매개변수이다. 
            그러면 식
            <span class="tooltip"><b>(9)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}$$
              </span>
            </span>
            를 통해 
            $\Delta C \approx -\eta
            \nabla C \cdot \nabla C = -\eta \|\nabla C\|^2$
            를 알 수 있다. 
            식 <span class="tooltip"><b>(10)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta v = -\eta \nabla C \nonumber\end{eqnarray}$$
              </span>
            </span>
            에 따라 $v$가 변한다면 
            $\| \nabla C \|^2 \geq 0$이므로 $\Delta C \leq 0$이되므로 $C$는 증가하지 않고 항상 감소합니다. 
            (물론 식
            <span class="tooltip"><b>(9)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}$$
              </span>
            </span>
            에서 근사 경계 안에서) 
            이는 정확히 우리가 구하고자 하는 특성입니다. 
            그래서 식 
            <span class="tooltip"><b>(10)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta v = -\eta \nabla C \nonumber\end{eqnarray}$$
              </span>
            </span>
            을 경사 하강 알고리즘에서 공의 "운동 법칙"을 정의한다. 
            즉, 식 
            <span class="tooltip"><b>(10)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta v = -\eta \nabla C \nonumber\end{eqnarray}$$
              </span>
            </span>
            을 사용하여 $\Delta v$에 대한 값을 계산하고, 공의 위치 $v$를 그 값만큼 움직인다. 
            $$\begin{eqnarray}
            v \rightarrow v' = v -\eta \nabla C.
            \tag{11}\end{eqnarray}$$
            이 새로운 규칙을 사용해 다시 움직인다. 
            이를 계속 반복하면 $C$를 감소시켜 전역 최솟값에 도달할 수 있다.  
          </p>

          <p>
            요약하면, 경사 하강 알고리즘은 반복적으로 경사 $\nabla C$을 계산하여 계곡 경사로 떨어지는 반대방향으로 움직인다.  
            이를 아래처럼 시각화할 수 있다.
            <br /><br />
            <img class="contentimg" src="./images/chapter1/valley_with_ball.png" alt="digits" width="500px">
            <br /><br />
            이 규칙으로 경사 하강이 현실 세계의 물리 운동을 만들지는 않는다. 
            현실 세계에서 공은 가속도를 가지고 가속도는 경사를 가로질러 굴러가거나 잠시나마 언덕위로 굴러가도록 만든다. 
            공이 계곡을 따라 굴러 내려간다는 것이 보장된다는 마찰 효과 후에 일어난다. 
            그에 반해, $\Delta v$를 고르는 규칙은 "지금 바로 내려가라"고 말해준다. 
            최솟값을 찾는데 여전히 좋은 규칙이다. 
          </p>

          <p>
            경사 하강이 올바르게 동작하려면 학습률 $\eta$를 충분히 작은 값으로 골라 식
            <span class="tooltip"><b>(9)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}$$
              </span>
            </span>
            가 좋은 근사를 갖도록 해야한다. 
            그렇지 않으면 $\Delta C > 0$가 되어 좋지 못한 결과를 얻는다. 
            동시에 $\eta$가 너무 작아지면 $\Delta v$의 변화가 매우 작아져 경사 하강 알고리즘의 동작은 느려진다. 
            실제 구현에서는 식 
            <span class="tooltip"><b>(9)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}$$
              </span>
            </span>
            는 좋은 근사를 갖도록하는 $\eta$는 다양하지만 알고리즘은 느리지 않다. 
            어떻게 동작하는지 뒤에서 살펴보자.
          </p>

          <p>
            $C$가 두 개의 변수에 대한 함수 일때 경사 하강 알고리즘을 설명했다. 
            하지만 사실 $C$가 많은 수의 변수를 가질때에도 잘 동작한다. 
            특히 $m$개의 변수 $v_1,\ldots,v_m$에 대한 함수 $C$를 가정하자. 
            그러면 작은 변화 $\Delta v = (\Delta v_1, \ldots, \Delta v_m)^T$에 의한 $C$에서의 변화 $\Delta C$는 다음과 같다. 
            
            $$\begin{eqnarray} 
            \Delta C \approx \nabla C \cdot \Delta v,
            \tag{12}\end{eqnarray}$$

            여기서 $\nabla C$는 다음의 벡터이다. 

            $$\begin{eqnarray}
            \nabla C \equiv \left(\frac{\partial C}{\partial v_1}, \ldots, 
            \frac{\partial C}{\partial v_m}\right)^T.
            \tag{13}\end{eqnarray}$$

            두 개의 변수의 경우처럼 $\Delta v$를 고를 수 있다. 

            $$\begin{eqnarray}
            \Delta v = -\eta \nabla C,
            \tag{14}\end{eqnarray}$$

            그리고 $\Delta C$는 음수이므로 (근사)식
            <span class="tooltip"><b>(12)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}$$
              </span>
            </span>
            는 보장된다. 
            이를 통해 $C$가 다변수 함수일때에도 새로운 규칙을 반복적으로 적용해 경사가 최솟값을 찾도록 할 수 있다. 

            $$\begin{eqnarray}
            v \rightarrow v' = v-\eta \nabla C.
            \tag{15}\end{eqnarray}$$

            이 새로운 규칙을 경사 하강 알고리즘을 정의로 생각할 수 있다. 
            이 새로운 규칙은 함수 $C$의 최솟값을 찾으려고 위치 $v$를 반복적으로 바꾸는 방법을 제시한다. 
            이 규칙은 항상 동작하지는 않는다. 
            몇몇 경우 잘못된 동작을 하며 경사하강은 $C$의 전역 최솟값을 찾지 못한다. 
            이는 뒤이은 챕터에서 살펴보겠다. 
            하지만 실제 경사 하강은 잘 동작하며 신경망에서 비용함수를 최소화하는 강력한 방법이다. 
            그리고 신경망의 학습을 돕는다. 
          </p>

          <p>
            경사 하강은 최솟값을 찾는 최적 전략인 면이 있다. 
            $C$를 가능한 많이 감소시키기 위해 위치에서 $\Delta v$를 움직인다고 가정하자. 
            이는 $\Delta C \approx \nabla C \cdot \Delta v$를 최소화하는 것과 같다. 
            어떤 고정된 값 $\epsilon > 0$에 대한 $\| \Delta v \| = \epsilon$를 만족하도록 위치 변화의 크기를 제한해보자. 
            즉, 고정된 크기로 위치를 변화시키고 $C$가 가능한 많이 감소하는 위치 변화 방향을 찾고자 한다. 
            $\nabla C \cdot \Delta v$를 최소화하는 $\Delta v$는 $\Delta v = - \eta \nabla C$라는 것을 증명할 수 있다. 
            여기서 $\eta = \epsilon / \|\nabla C\|$는 크기 제한 $\|\Delta v\| = \epsilon$이 결정한다. 
            그래서 경사 하강은 $C$를 가장 많이 감소하는 방향으로 내려가는 방법이라 할 수 있다.  
          </p>

          <br />
          <h2>예제</h2>

          <p>
            <ul>
              <li>
                <p>
                  이전 단락의 주장을 증명하라. 
                  힌트: 쿄시-슈바르츠 부등식을 이용하라. 
                </p>
              </li>
              
              <li>
                <p>
                  함수 $C$가 이변수 함수인 경우와 다변수 함수인 경우에 대해 경사 하강 알고리즘을 설명하였다. 
                  함수 $C$가 일변수 함수인 경우 무슨 일이 일어나는가? 
                  일차원인 경우 경사 하강 알고리즘의 동작을 기하학적으로 해석할 수 있나?
                </p>
              </li>
            </ul>
          </p>

          <p>
            사람들은 실제 물리 현상을 모방한 것을 포함한 경사 하강 알고리즘의 변형들을 많이 연구했다. 
            공의 움직임을 모방한 변형은 어떤 면에서 이점을 가지지만 주요한 단점 또한 가진다. 
            $C$의 이차 편미분을 계산해야 하며 이는 비용이 많이 든다. 
            비용이 많이 드는 이유를 살펴보자. 
            모든 이차 편도함수 $\partial^2 C/ \partial v_j \partial v_k$ 을 계산한다고 가정하자. 
            변수 $v_j$ 가 백 만개 있다면 백만의 제곱인 일억 번의 이차 편도함수 계산을 해야한다. 
            이를 계산하는 비용은 많이 든다. 
            그렇지만 이런 문제를 피하는 몇 가지 속임수가 있고, 경사 하강에 대한 대안을 찾는 것은 현재 활발하게 연구되고 있는 분야이다. 
            하지만 이 책에서 신경망 학습에 대한 방법으로 경사 하강과 그의 변형을 살펴볼 것이다. 
          </p>

          <p>
            신경망을 학습시키기 위해 경사 하강을 어떻게 적용할 수 있을까? 
            식 

            <span class="tooltip"><b>(6)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray}  C(w,b) \equiv
                \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}$$
              </span>
            </span>

            에서 비용을 최소화 하는 가중치 $w_k$ 와 편향 $b_l$ 을 찾기위해 경사 하강을 사용하는 것이 기본적인 생각이다. 
            어떻게 동작하는지 살펴보기 위해 경사 하강 갱신 규칙을 $v_j$를 치환하여 가중치와 편향으로 다시 써보자. 
            즉, "위치"는 $w_k$ 와 $b_l$ 을 가지며 경사 벡터 $\nabla C$ 는 상응하는 $\partial C / \partial w_k$ 와 $\partial C / \partial b_l$ 을 가진다. 
            경사 하강 갱신 규칙을 위의 요소들로 다시 쓰면 다음과 같다. 

            $$\begin{eqnarray}
            w_k & \rightarrow & w_k' = w_k-\eta \frac{\partial C}{\partial w_k} \tag{16}\\
            b_l & \rightarrow & b_l' = b_l-\eta \frac{\partial C}{\partial b_l}.
            \tag{17}\end{eqnarray}$$

            이 갱신 규칙을 반복적으로 적용하여 "언덕 아래로 굴러 내려"갈 수 있으며, 비용함수의 최솟값을 찾을 수 있다. 
            다시 말해, 이것이 바로 신경망에서 학습을 하는데 사용할 수 있는 규칙이다. 
          </p>

          <p>
            경사 하강 규칙을 적용하는데 몇 가지 어려움이 있다. 
            책의 뒷 부분에서 어려움을 깊이 살펴보도록 하자. 
            당분간은 한 가지 문제에 대해 말하고자 한다. 
            문제가 무엇인지 이해하기 위해 식

            <span class="tooltip"><b>(6)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray}  C(w,b) \equiv
                \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}$$
              </span>
            </span>

            에서 이차 비용함수를 다시 살펴보자. 
            이 비용함수는 $C = \frac{1}{n} \sum_x C_x$ 과 같은 형태를 가지며, 이는 각각의 학습 데이터에 대한 비용 $C_x \equiv \frac{\|y(x)-a\|^2}{2}$ 의 평균이다. 
            실제로 $\nabla C$ 을 계산하려면 각각의 학습 데이터 입력 $x$ 에 대해 개별적으로 $\nabla C_x$ 을 계산한 다음 평균해야한다. 
            그러면 $\nabla C = \frac{1}{n} \sum_x \nabla C_x$ 이 된다. 
            하지만 학습 데이터 입력 수가 많으면 계산이 오래 걸리며 학습은 매우 느리게 일어난다.  
          </p>

          <p>
            확률적 경사 하강(stochastic gradient descent)을 이용하면 학습을 빨리 할 수 있다. 
            무작위로 고른 학습 데이터 입력에 대해 $\nabla C_x$ 을 계산하여 $\nabla C$ 을 계산하는 것이 아이디어이다. 
            이 작은 표본을 평균하여 $\nabla C$ 의 빨리 측정할 수 있으며 이는 경사 하강 속도를 높이고 학습 속도 또한 빠르게 한다. 
          </p>

          <p>
            이 아이디어를 더 정확하게 써보면, 확률적 경사 하강은 무작위로 고른 학습 데이터 입력 $m$ 개를 선택하여 동작한다. 
            이렇게 무작위로 뽑힌 학습 데이터 입력을 $X_1, X_2, \ldots, X_m$ 이라 하고, 이들을 미니 배치(mini-batch)라 하자. 
            표본 크기 $m$이 충분히 크면 $\nabla C_{X_j}$ 의 평균 값은 모든 $\nabla C_x$ 값의 평균과 대략적으로 같아진다. 
            식으로 쓰면 다음과 같다. 

            $$\begin{eqnarray}
            \frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \frac{\sum_x \nabla C_x}{n} = \nabla C,
            \tag{18}\end{eqnarray}$$

            여기서 두 번째 합은 학습 데이터 전체에 대한 합이다. 
            양 변을 바꿔서 쓰면 다음과 같다. 

            $$\begin{eqnarray}
            \nabla C \approx \frac{1}{m} \sum_{j=1}^m \nabla C_{X_{j}},
            \tag{19}\end{eqnarray}$$

            무작위로 고른 미니 배치에 대한 경사를 계산하여 전체 경사를 측정할 수 있다는 점을 확인하자. 
          </p>

          <p>
            이를 신경망 학습과 연관시켜보자. 
            $w_k$ 와 $b_l$ 을 신경망의 가중치와 편향이라 가정하자. 
            그러면 확률적 경사 하강은 무작위로 선택한 학습 입력 미니 배치를 뽑아서 동작한다. 
            그리고 다음의 식으로 학습을 진행한다. 

            $$\begin{eqnarray} 
            w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
            \sum_j \frac{\partial C_{X_j}}{\partial w_k} \tag{20}\\
            
            b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
            \sum_j \frac{\partial C_{X_j}}{\partial b_l},
            \tag{21}\end{eqnarray}$$

            여기서 합은 현재 미니 배치에서 모든 학습 입력 $X_j$ 에 대한 합이다. 
            그런 다음 무작위로 선택한 다른 미니 배치를 골라 학습한다. 
            학습 입력 데이터가 고갈될 때 까지 학습을 진행하며 이는 학습의 한 세대(an epoch of training)를 완료했다고 말한다. 
            이 시점에서 새로운 학습 세대를 시작한다. 
          </p>

          <p>
            덧붙여 말하자면 비용 함수의 조정과 가중치와 편향을 갱신하는 미니 배치의 조정에 다양한 규칙이 있다는 점을 생각해야 한다. 
            식 

            <span class="tooltip"><b>(6)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray}  C(w,b) \equiv
                \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}$$
              </span>
            </span>

            에서 전체 비용 함수를 $\frac{1}{n}$ 해주었다. 
            평균이 아닌 개별 학습 데이터에 대한 합을 계산할 때 $\frac{1}{n}$ 을 빼먹는 경우가 많다. 
            전체 학습 데이터 개수가 알려지지 않은 경우에는 유용하다. 
            예를 들어 실시간으로 학습 데이터가 만들어지는 경우 이를 이용할 수 있다. 
            그리고 비슷한 방법으로 미니 배치는 규칙 

            <span class="tooltip"><b>(20)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
                \sum_j \frac{\partial C_{X_j}}{\partial w_k}  \nonumber\end{eqnarray}$$
              </span>
            </span>

            과

            <span class="tooltip"><b>(21)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray}  
                b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
                \sum_j \frac{\partial C_{X_j}}{\partial b_l} \nonumber\end{eqnarray}$$
              </span>
            </span>

            을 갱신 할때 합 앞에 $\frac{1}{m}$ 을 빼먹는 경우가 있다. 
            학습률 $\eta$ 를 조정하는 것과 동등하므로 개념적으로 큰 차이는 없다. 
            하지만 다른 작업들을 상세히 비교할 때 살펴볼 가치가 있다. 
          </p>

          <p>
            확률적 경사 하강을 정치적인 여론 조사로 생각 할 수 있다. 
            전체 선거를 진행하는 것보다 여론 조사를 진행하는 것이 쉬운 것처럼 전체 배치에 대해 경사 하강을 적용하는 것보다 표본인 미니 배치에 대해 적용하는 것이 훨씬 쉽다. 
            예를 들어 MNIST처럼 학습 데이터 크기가 $n = 60,000$ 인 경우 미니 배치 크기를 $m = 10$ 으로 하면 경사를 측정하는데 $6,000$ 배 빠르게 할 수 있다. 
            물론, 통계적인 변동이 있을 수 있으므로 측정이 완벽하지는 않지만 완벽할 필요는 없다. 
            우리에게 필요한 것은 $C$ 를 감소시키는 일반적인 방향에 대한 움직임이다. 
            이는 경사의 계산을 정확하게 할 필요는 없다는 것을 의미한다. 
            실제로 확률적 경사 하강은 흔히 쓰이는 방법이고 신경망을 학습하는데 강력한 기술이다. 
            그리고 이 책에서 살펴볼 학습 방법의 기본이 된다.  
          </p>

          <br />
          <h2>예제</h2>

          <p>
            <ul>
              <li>
                <p>
                  경사 하강의 극단적인 예는 미니 배치 크기를 1로 하는 것이다. 
                  즉, 학습 데이터 입력 $x$ 가 주어지고 가중치와 편향을 $w_k \rightarrow w_k' = w_k - \eta \partial C_x / \partial w_k$ 과 $b_l \rightarrow b_l' = b_l - \eta \partial C_x / \partial b_l$ 에 따라 갱신한다. 
                  그런 다음 다른 학습 데이터를 고르고 가중치와 편향을 다시 갱신한다. 
                  이 과정을 계속 반복한다. 
                  이 절차를 온라인 학습 또는 증분식 학습(online, on-line, or incremental learning)이라 한다. 
                  온라인 학습에서 신경망은 한 번에 하나의 학습 데이터를 이용해 학습한다. 
                  미니 배치 크기가 20인 확률적 경사 하강과 비교하여 온라인 학습의 장점과 단점을 서술하여라. 
                </p>
              </li>
            </ul>
          </p>

          <p>
            경사 하강을 처음 접하는 사람들을 괴롭히는 점들을 설명하면서 이 절을 마무리하려 한다. 
            신경망에서 비용 함수 $C$는 모든 가중치와 편향을 변수로 하는 다변수 함수이고 어떤 점에서는 고차원 공간에서 면을 정의한다. 
            몇몇 사람들은 다음과 같은 생각에 마주한다. 
            "이 차원을 시각화할 수 있어야한다."
            그리고 다음과 같은 걱정을 한다. 
            "5차원은 커녕 사차원도 상상할 수 없다."
            진정한 수학자가 가지는 어떤 특별한 능력이 있을까? 
            물론 없다. 
            전문적인 수학자라 할지라도 사차원을 시각화할 수 없다. 
            대신 수학자들이 무슨 일이 일어나는지 표시하기 위해 다른 방법을 사용한다. 
            그것은 바로 우리가 위에서 살표본 것들이다. 
            $C$ 를 감소시키기 위해 어떻게 움직이는지 이해하려고 $\Delta C$ 를 표현하는 시각적 표현 대신에 수식을 사용했다. 
            고차원을 생각하는데 뛰어난 사람들은 이러한 것을 따라 다양한 기술들을 가지고 있다. 
            수학적 표현은 하나의 예이다. 
            이러한 기술은 삼차원을 시각화하는 것 만큼 단순함을 가지지 못하지만 이러한 기술을 한 번 습득하면 고차원을 아주 잘 생각할 수 있다. 
            여기서는 더 깊게 들어가지 않겠다. 
            하지만 수학자가 고차원을 생각하는 방법에 대한 <a href="https://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking">다음 글</a>을 읽어보면 좋다. 
            몇몇 기술은 꽤 복잡하지만 대부분의 내용은 직간적이며 누구나 공부할 수 있다.  
          </p>

          <br />
          <h2>숫자를 분류하는 신경망 구현하기</h2>
          <hr>

          <p>
            확률적 경사 하강과 MNIST 학습 데이터를 이용해서 손글씨 숫자를 인식하는 방법을 학습하는 프로그램을 작성해보자. 
            파이썬 (2.7) 프로그램을 이용해 단 74줄의 코드로 작성하겠다. 
            먼저 필요한 것은 MNIST 데이터이다. 
            git 사용자라면 이 책의 코드 저장소를 클론(cloning)해서 데이터를 얻을 수 있다. 
            git 사용자가 아니라면 <a href="https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip">여기서</a> 데이터와 코드를 다운받을 수 있다. 
          </p>

          <p>
            MNIST 데이터를 처음에 설명할 때 $60,000$ 개의 학습 이미지와 $10,000$ 개의 테스트 이미지로 구성된다고 했다. 
            이것이 공식적인 MNIST이다. 
            사실 여기서는 데이터를 조금 다른 방식으로 나눌 것이다. 
            테스트 이미지는 그대로 남겨두고 $60,000$ 개의 학습 데이터를 두 부분으로 나누겠다. 
            $50,000$ 개의 이미지를 이용해 신경망을 학습시키고, 다른 $10,000$ 개의 이미지를 검증 데이터셋(validation set)으로 사용하겠다. 
            이 장에서는 검증 데이터를 사용하지 않을거다. 
            하지만 책의 뒷 부분에서 학습률과 같은 신경망의 하이퍼파라미터(hyper-parameters)를 설정하는 방법을 찾는데 검증 데이터셋을 이용할 것이다. 
            하이퍼파라미터는 학습 알고리즘이 직접 선택하지 않는다. 
            검증 데이터는 원래의 MNIST 데이터의 한 부분이 아니지만 대부분의 사람들은 이러한 방식으로 MNIST를 이용하고 검증 데이터의 사용은 신경망에서 흔한 방법이다. 
            앞으로 "MNIST 학습 데이터"는 $60,000$ 개의 원본 이미지 데이터셋
            <span class="tooltip"><b>*</b>
              <span class="tooltiptext">
                As noted earlier, the MNIST data set is based on two data sets collected by NIST, <br />
                the United States' National Institute of Standards and Technology. <br />
                To construct MNIST the NIST data sets were stripped down and <br />
                put into a more convenient format by Yann LeCun, Corinna Cortes, <br />
                and Christopher J. C. Burges. See this link for more details. <br />
                The data set in my repository is in a form that makes it easy <br />
                to load and manipulate the MNIST data in Python. <br />
                I obtained this particular form of the data <br /> 
                from the LISA machine learning laboratory <br /> 
                at the University of Montreal (link). 
              </span>
            </span>
            이 아닌 $50,000$ 개의 이미지 데이터 셋을 의미한다.  
          </p>

          <p>
            MNIST 데이터외에 선형대수 계산을 빨리 하기위해 <a href="http://www.numpy.org/">Numpy</a>라 불리는 파이썬 라이브러리가 필요하다. 
            Numpy 설치는 <a href="https://www.scipy.org/install.html">여기서</a> 할 수 있다. 
          </p>

          <p>
            전체 코드를 보여주기에 앞서 신경망 코드의 핵심적인 특징을 설명하려 한다. 
            주목할만한 부분은 <code>Network</code> 클래스이다.
            이를 이용해 신경망을 표현한다. 
            아래 코드를 이용해 <code>Network</code> 객체를 초기화한다. 

            <pre class="prettyprint linenums:1"><code class="language-python"></code>class Network(object):
    def __init__(self, sizes):
        self.num_layers = len(sizes)
        self.sizes = sizes
        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
        self.weights = [np.random.randn(y, x) 
            for x, y in zip(sizes[:-1], sizes[1:])]</code></pre>

            이 코드에서 리스트 <code>sizes</code>는 각 층의 뉴런 수를 나타낸다. 
            예를 들어, 첫 번째 층에 2개의 뉴런, 두 번째 층에 3개의 뉴런, 마지막 층에 1개의 뉴런을 가진 <code>Network</code> 객체를 만드려면 아래와 같은 코드를 작성하면 된다. 

            <pre class="prettyprint linenums:1"><code class="language-python"></code>    net = Network([2, 3, 1])</code></pre>

            <code>Network</code> 객체에서 편향과 가중치는 모두 무작위로 초기화된다. 
            초기화를 할때 Numpy <code>np.random.randn</code> 함수를 하영하여 평균은 $0$ 이고 표준 편차가 $1$ 인 가우스 분포를 생성한다. 
            이 무작위 초기화는 확률적 경사 하강 알고리즘의 시작점이 된다. 
            이 장의 뒷부분에서 가중치와 편향을 초기화하는 더 좋은 방법을 살펴볼 것이다. 
            하지만 당분간은 이렇게 한다. 
            <code>Network</code> 초기화 코드는 첫 번째 뉴런층은 입력층이라 가정하고 이 뉴런에 대한 편향 값 설정은 하지 않는다. 
            편향은 이 후의 층에서 출력을 계산할 때만 사용되기 때문이다. 
          </p>

          <p>
            Numpy 행렬의 리스트에 가중치와 편향이 저장된다. 
            예를 들어 <code>net.weights[1]</code>은 두 번째와 세 번째 뉴런 층을 연결하는 가중치를 저장하는 Numpy 행렬이다. 
            (파이썬 리스트의 인덱스는 <code>0</code>부터 시작하므로 이는 첫 번째와 두 번째 층 연결이 아니다.) 
            <code>net.weights[1]</code>을 단순하게 행렬 $w$ 로 표기하자. 
            $w_jk$ 는 두 번째 층의 $k^{\rm th}$ 번째 뉴런과 세 번째 층의 $j^{\rm th}$ 번째 뉴런을 연결하는 가중치이다. 
            인덱스 $j$ 와 $k$ 의 순서는 다소 어색할 수 있다. 
            $j$ 와 $k$ 의 순서를 바꾸는 것이 더 말이 될 수도 있다.
            이러한 순서를 사용하는 이점은 세 번째 층의 활성 벡터는 다음과 같다는 의미이다. 
            
            $$\begin{eqnarray} 
            a' = \sigma(w a + b).
            \tag{22}\end{eqnarray}$$

            위 식은 많은 것을 포함하므로 조금 더 풀어써보자. 
            $a$ 는 두 번째 층의 뉴런을 활성화하는 벡터이다. 
            $a'$ 을 얻기 위해 $a$ 에 가중치 행렬 $w$ 를 곱하고 편향 벡터 $b$ 를 더한다. 
            그런 다음 벡터 $w a +b$ 의 모든 원소에 함수 $\sigma$ 를 적용한다. 
            (이는 함수 $\sigma$ 를 벡터화(vectorizing)한다고 불린다.) 
            시그모이드 뉴런의 출력을 계산할 때 식 
            <span class="tooltip"><b>(22)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                a' = \sigma(w a + b) \nonumber\end{eqnarray}$$
              </span>
            </span>
            는 이전의 규칙 식
            <span class="tooltip"><b>(4)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}$$
              </span>
            </span>
            와 같은 결과를 준다는 사실을 쉽게 증명할 수 있다. 
          </p>

          <br />
          <h2>예제</h2>

          <p>
            <ul>
              <li>
                <p>
                  식
                  <span class="tooltip"><b>(22)</b>
                    <span class="tooltiptext">
                      $$\begin{eqnarray} 
                      a' = \sigma(w a + b) \nonumber\end{eqnarray}$$
                    </span>
                  </span>
                  를 원소 형태로 쓰고 시그모이드 뉴런의 출력을 계산하는 규칙 
                  <span class="tooltip"><b>(4)</b>
                    <span class="tooltiptext">
                      $$\begin{eqnarray} 
                      \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}$$
                    </span>
                  </span>
                  와 같은 결과를 주는 것을 증명해라. 
                </p>
              </li>
            </ul>
          </p>

          <p>
            이 모든 것을 고려해서 <code>Network</code> 인스턴스(instance)에서 출력을 계산하는 코드를 작성하는 것은 쉽다.
            시그모이드 함수 정의로 시작하자. 
            <pre class="prettyprint linenums:1"><code class="language-python"></code>    def sigmoid(z):
        return 1.0/(1.0+np.exp(-z))</code></pre>
            입력 $z$ 가 벡터이거나 Numpy array일 때 Numpy는 자동으로 <code>sigmoid</code> 함수를 원소별로 적용해서 벡터 형태로 출력한다. 
          </p>

          <p>
            그 다음 <code>Network</code> 클래스에 <code>feedforward</code> 메소드를 추가한다. 
            신경망에 대한 입력이 주어지면 상응하는 출력
            <span class="tooltip"><b>*</b>
              <span class="tooltiptext">
                블라블라블라
              </span>
            </span>
            을 반환하는 메소드이다. 
            메소드가 하는 일은 각 층에 식 
            <span class="tooltip"><b>(22)</b>
              <span class="tooltiptext">
                $$\begin{eqnarray} 
                a' = \sigma(w a + b) \nonumber\end{eqnarray}$$
              </span>
            </span>
            를 적용하는 것이다. 

            <pre class="prettyprint linenums"><code class="language-python">    def feedforward(self, a):
    """Return the output of the network if "a" is input."""
      for b, w in zip(self.biases, self.weights):
          a = sigmoid(np.dot(w, a)+b)
          return a</code></pre>

            물론 <code>Network</code> 객체가 주로 하는 일은 학습을 하는 것이다. 
            그러기 위해서 확률적 경사 하강을 구현하는 <code>SGD</code> 메소드를 작성하자. 
            아래에 코드가 있다. 
            이해가 어려운 부분이 몇 군데 있지만 아래 부분에서 세세하게 다루겠다. 


            <pre class="prettyprint linenums"><code class="language-python">    def SGD(self, training_data, epochs, mini_batch_size, eta,
            test_data=None):
        """Train the neural network using mini-batch stochastic
        gradient descent.  The "training_data" is a list of tuples
        "(x, y)" representing the training inputs and the desired
        outputs.  The other non-optional parameters are
        self-explanatory.  If "test_data" is provided then the
        network will be evaluated against the test data after each
        epoch, and partial progress printed out.  This is useful for
        tracking progress, but slows things down substantially."""
        if test_data: n_test = len(test_data)
        n = len(training_data)
        for j in xrange(epochs):
            random.shuffle(training_data)
            mini_batches = [
                training_data[k:k+mini_batch_size]
                for k in xrange(0, n, mini_batch_size)]
            for mini_batch in mini_batches:
                self.update_mini_batch(mini_batch, eta)
            if test_data:
                print "Epoch {0}: {1} / {2}".format(
                    j, self.evaluate(test_data), n_test)
            else:
                print "Epoch {0} complete".format(j)</code></pre>
            
            <code>training_data</code>는 학습 데이터 입력과 상응하는 출력을 나타내는 튜플 <code>(x, y)</code>의 리스트이다. 
            변수 <code>epochs</code>와 <code>mini_batch_size</code>는 학습을 진행하는 세대의 수와 표본을 추출할 때 사용하는 미니 배치의 크기를 의미한다. 
            <code>eta</code>는 학습률 $\eta$이다. 
            옵션 인자 <code>test_data</code>가 주어지면 프로그램은 학습 세대 마다 신경망을 평가하고, 부분적인 진행 상황을 출력한다. 
            이는 진행 상황을 보는데 유용하지만 성능은 상당히 느려진다. 
          </p>

          <p>
            코드는 다음처럼 동작한다. 
            각 세대마다 학습 데이터를 무작위로 섞으면서 시작한다. 
            그리고 적절한 크기의 미니 배치로 나눈다. 
            이는 학습 데이터에서 무작위로 표본을 추출하는 쉬운 방법이다. 
            코드 <code>self.update_mini_batch(mini_batch, eta)</code> 부분이 이를 실행하며 <code>mini_batch</code>에서 학습 데이터를 사용하여 경사 하강의 반복에 따라 신경망의 가중치와 편향을 갱신한다. 
            <code>update_mini_batch</code> 메소드에 대한 코드는 아래와 같다. 

            <pre class="prettyprint linenums"><code class="language-python">    def update_mini_batch(self, mini_batch, eta):
        """Update the network's weights and biases by applying
        gradient descent using backpropagation to a single mini batch.
        The "mini_batch" is a list of tuples "(x, y)", and "eta"
        is the learning rate."""
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [w-(eta/len(mini_batch))*nw 
                        for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb 
                        for b, nb in zip(self.biases, nabla_b)]</code></pre>

            아래의 코드가 대부분의 작업을 수행한다. 
            <pre class="prettyprint linenums"><code class="language-python">            delta_nabla_b, delta_nabla_w = self.backprop(x, y)</code></pre>

            이 코드는 역전파 알고리즘(backpropagation algorithm)을 호출한다. 
            이 알고리즘은 비용 함수의 경사를 빠르게 계산한다. 
            <code>update_mini_batch</code>는 <code>mini_batch</code>에서 모든 학습 데이터에 대한 경사를 계산한다. 그리고 <code>self.weights</code>와 <code>self.biases</code>를 갱신한다. 
          </p>

          <p>
            <code>self.backprop</code>에 대한 코드를 지금 당장 보여주지는 않을 것이다. 
            다음 장에서 역전파 알고리즘이 어떻게 동작하는지 공부하고 <code>self.backprop</code>에 대한 코드를 추가해보자. 
            당분간은 위에서 말한대로 역전파 알고리즘이 동작한다고 가정하고 학습 데이터 $x$와 연관된 비용에 대한 경사를 반환한다.
          </p>

          <p>
            위에서 생략한 문서화 문자열을 포함한 전체 프로그램을 보자. 
            <code>self.backprop</code>을 제외하고 프로그램에 대해 설명해보자. 
            앞서 말한 <code>self.SGD</code>와 <code>self.update_mini_batch</code>가 대부분의 일을 한다. 
            <code>self.backprop</code> 메소드는 경사를 계산하는데 도움을 주기 위해 다른 함수들을 이용한다. 
            $\sigma$ 함수의 도함수를 계산하는 <code>sigmoid_prime</code>과 여기서 설명하지 않을 <code>self.cost_derivative</code>가 있다. 
            코드와 문서화 문자열을 보면 핵심을 자세히 알 수 있다. 
            다음 장에서 자세히 살펴보겠다. 
            프로그램의 길이가 길어 보이지만 코드 중 대부분은 이해를 돕기위한 문서화 문자열이다. 
            사실 프로그램은 여백과 주석을 제외하고 단지 74줄 밖에 되지 않는다. 
            모든 코드는 Github에서 볼 수 있다. 
          </p>

          <p>
            <pre class="prettyprint linenums"><code class="language-python">"""
network.py
~~~~~~~~~~
 
A module to implement the stochastic gradient descent learning
algorithm for a feedforward neural network.  Gradients are calculated
using backpropagation.  Note that I have focused on making the code
simple, easily readable, and easily modifiable.  It is not optimized,
and omits many desirable features.
"""
  
#### Libraries
# Standard library
import random

# Third-party libraries 
import numpy as np 
 
class Network(object):

    def __init__(self, sizes):
        """The list ``sizes`` contains the number of neurons in the
        respective layers of the network.  For example, if the list
        was [2, 3, 1] then it would be a three-layer network, with the
        first layer containing 2 neurons, the second layer 3 neurons,
        and the third layer 1 neuron.  The biases and weights for the
        network are initialized randomly, using a Gaussian
        distribution with mean 0, and variance 1.  Note that the first
        layer is assumed to be an input layer, and by convention we
        won't set any biases for those neurons, since biases are only
        ever used in computing the outputs from later layers."""
        self.num_layers = len(sizes)
        self.sizes = sizes
        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
        self.weights = [np.random.randn(y, x)
                        for x, y in zip(sizes[:-1], sizes[1:])]
                        
    def feedforward(self, a):
        """Return the output of the network if ``a`` is input."""
        for b, w in zip(self.biases, self.weights):
            a = sigmoid(np.dot(w, a)+b)
        return a
        
    def SGD(self, training_data, epochs, mini_batch_size, eta,
            test_data=None):
        """Train the neural network using mini-batch stochastic
        gradient descent.  The ``training_data`` is a list of tuples
        ``(x, y)`` representing the training inputs and the desired
        outputs.  The other non-optional parameters are
        self-explanatory.  If ``test_data`` is provided then the
        network will be evaluated against the test data after each
        epoch, and partial progress printed out.  This is useful for
        tracking progress, but slows things down substantially."""
        if test_data: n_test = len(test_data)
        n = len(training_data)
        for j in xrange(epochs):
            random.shuffle(training_data)
            mini_batches = [
                training_data[k:k+mini_batch_size]
                for k in xrange(0, n, mini_batch_size)]
            for mini_batch in mini_batches:
                self.update_mini_batch(mini_batch, eta)
            if test_data:
                print "Epoch {0}: {1} / {2}".format(
                    j, self.evaluate(test_data), n_test)
            else:
                print "Epoch {0} complete".format(j)
                
    def update_mini_batch(self, mini_batch, eta):
        """Update the network's weights and biases by applying
        gradient descent using backpropagation to a single mini batch.
        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``
        is the learning rate."""
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [w-(eta/len(mini_batch))*nw
                        for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb
                        for b, nb in zip(self.biases, nabla_b)]
                        
    def backprop(self, x, y):
        """Return a tuple ``(nabla_b, nabla_w)`` representing the
        gradient for the cost function C_x.  ``nabla_b`` and
        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar
        to ``self.biases`` and ``self.weights``."""
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        # feedforward
        activation = x
        activations = [x] # list to store all the activations, layer by layer
        zs = [] # list to store all the z vectors, layer by layer
        for b, w in zip(self.biases, self.weights):
            z = np.dot(w, activation)+b
            zs.append(z)
            activation = sigmoid(z)
            activations.append(activation)
        # backward pass
        delta = self.cost_derivative(activations[-1], y) * \
            sigmoid_prime(zs[-1])
        nabla_b[-1] = delta
        nabla_w[-1] = np.dot(delta, activations[-2].transpose())
        # Note that the variable l in the loop below is used a little
        # differently to the notation in Chapter 2 of the book.  Here,
        # l = 1 means the last layer of neurons, l = 2 is the
        # second-last layer, and so on.  It's a renumbering of the
        # scheme in the book, used here to take advantage of the fact
        # that Python can use negative indices in lists.
        for l in xrange(2, self.num_layers):
            z = zs[-l]
            sp = sigmoid_prime(z)
            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
            nabla_b[-l] = delta
            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
        return (nabla_b, nabla_w)
        
    def evaluate(self, test_data):
        """Return the number of test inputs for which the neural
        network outputs the correct result. Note that the neural
        network's output is assumed to be the index of whichever
        neuron in the final layer has the highest activation."""
        test_results = [(np.argmax(self.feedforward(x)), y)
                        for (x, y) in test_data]
        return sum(int(x == y) for (x, y) in test_results)
        
    def cost_derivative(self, output_activations, y):
        """Return the vector of partial derivatives \partial C_x /
        \partial a for the output activations."""
        return (output_activations-y)
        
#### Miscellaneous functions
def sigmoid(z):
    """The sigmoid function."""
    return 1.0/(1.0+np.exp(-z))
    
def sigmoid_prime(z):
    """Derivative of the sigmoid function."""
    return sigmoid(z)*(1-sigmoid(z))</code></pre>
          </p>

          <p>
            프로그램이 손글씨 숫자를 얼머나 잘 인식하는가? 
            먼저 MNIST 데이터를 로딩부터 시작해보자. 
            아래와 같은 <code>mnist_loader.py</code> 프로그램을 이용할 것이다. 
            파이썬 쉘에 다음의 명령어를 입력한다. 
            <pre class="prettyprint linenums"><code class="language-python">>>> import mnist_loader
>>> training_data, validation_data, test_data = \
... mnist_loader.load_data_wrapper()</code></pre>

            물론 별개의 파이썬 프로그램을 사용해도 된다. 
            하지만 파이썬 쉘에서 하는 것이 아마 더욱 쉬울 것이다. 
          </p>

          <p>
            MNIST 데이터를 로딩한 후 30개의 은닉 뉴런으로 <code>Network</code>를 구성할 것이다. 
            위에 있는 파이썬 프로그램 <code>Network</code>을 임포트해서 이를 구현할 것이다. 
            <pre class="prettyprint linenums"><code class="language-python">>>> import network
>>> net = network.Network([784, 30, 10])</code></pre>

            마지막으로 확률적 경사 하강을 이용해 MNIST 학습 데이터를 30 세대 동안 미니 배치 크기 10과 학습률 $\eta = 3.0$ 으로 학습한다. 
            <pre class="prettyprint linenums"><code class="language-python">>>> net.SGD(training_data, 30, 10, 3.0, test_data=test_data)</code></pre>
          </p>

          <p>
            위에서 본 것처럼 코드를 실행하면 실행하는데 약간의 시간이 걸린다. 
            2015년 기분의 전형적인 컴퓨터 기계에서 동작하는데 약 몇 분이 소요된다. 
            프로그램을 구동하고 계속해서 책을 읽으며 출력을 확인할 것을 추천한다. 
            시간이 없다면 세대 수를 줄이거나 은닉 뉴런의 수를 줄이거나 혹은 학습 데이터 중 일부를 사용하여 속도를 높일 수 있다. 
            상업적 용도로 이용되는 코드는 훨씬 더 빠르다. 
            위의 파이썬 코드는 신경망이 어떻게 동작하는지 이해를 돕기위해 작성되어 높은 성능을 보이지 않는다. 
            물론 한 번 신경망을 학습시키면 어떤 계산 플랫폼에서도 매우 빠르게 동작한다. 
            예를 들어 일단 신경망에 대한 가중치와 편향을 학습했다면 웹 브라우저의 Javascript나 모바일 장치의 어플리케이션에서 쉽게 동작할 수 있다. 
            어쨌든 신경망의 학습 진행 중 출력의 일부가 아래에 있다. 
            보다시피 한 세대가 후에 $10,000$ 중 $9,129$ 에 도달했고 숫자는 점점 증가한다. 

            <pre class="prettyprint linenums"><code class="language-python">Epoch 0: 9129 / 10000
Epoch 1: 9295 / 10000
Epoch 2: 9348 / 10000
...
Epoch 27: 9528 / 10000
Epoch 28: 9542 / 10000
Epoch 29: 9534 / 10000</code></pre>

            즉, 학습된 신경망은 약 $95%$ 의 분류률을 보인다. 
            28번 째 세대에서 $95.42%$ 로 최고점을 찍는다. 
            첫 번째 시도에 꽤나 큰 성과이다. 
            하지만 코드를 실행하면 책의 결과와 완전히 똑같이 않을 것이다. 
            무작위로 선택하여 다른 가중치와 편향을 이용하여 신경망을 초기화하기 때문이다. 
            이 장에서 결과를 만들기 위해 세 번의 결과 중 가장 좋은 것을 가져왔다.
          </p>

          <p>
            위의 실험으로 돌아가 은닉층의 뉴런의 수를 $100$ 개로 바꿔보자. 
            앞서 말했듯이 코드를 실행하면 시간이 꽤 걸린다. 
            (내 컴퓨터에서는 각 학습 세대마다 수십초의 시간이 걸렸다.)
            그래서 코드를 실행시켜 놓고 계속해서 책을 읽어 나가면 된다. 

            <pre class="prettyprint linenums"><code class="language-python">>>> net = network.Network([784, 100, 10])
>>> net.SGD(training_data, 30, 10, 3.0, test_data=test_data)</code></pre>

            아니나 다를까 이는 결과를 $96.59%% 까지 향상시켰다. 
            적어도 이 경우에 은닉층에서 더 많은 수의 뉴런을 사용해서 좋은 결과를 얻을 수 있다. 
            <span class="tooltip"><b>*</b>
              <span class="tooltiptext">
                블라블라블라
              </span>
            </span>
          </p>

          <p>
            물론 이러한 정확도를 얻기 위해서는 학습 세대의 수, 미니 배치 크기, 학습률 $\eta$를 특정 값으로 선택해야한다. 
            위에서 말한 것처럼 이는 신경망에 대한 하이퍼파라미터로 알려져 있고, 학습 알고리즘이 배우는 매개 변수인 가중치와 편향과는 구별된다. 
            하이퍼파라미터를 적절히 선택하지 못하면 결과는 나빠진다. 
            예를 들어, 학습률 $\eta = 0.001$ 로 설정했다고 가정하자. 

            <pre class="prettyprint linenums"><code class="language-python">>>> net = network.Network([784, 100, 10])
>>> net.SGD(training_data, 30, 10, 0.001, test_data=test_data)</code></pre>

            결과는 썩 좋지 못하다. 

            <pre class="prettyprint linenums"><code class="language-python">Epoch 0: 1139 / 10000
Epoch 1: 1136 / 10000
Epoch 2: 1135 / 10000
...
Epoch 27: 2101 / 10000
Epoch 28: 2123 / 10000
Epoch 29: 2142 / 10000</code></pre>

            그러나 신경망의 성능은 더디지만 시간이 지날수록 좋아진다. 
            이는 학습률을 $\eta = 0.01$ 과 같이 올려야 한다는 것을 암시한다. 
            그렇게 하면 더 좋은 결과를 얻을 수 있고, 이는 다시 학습률을 올릴 것을 의미한다. 
            (변화가 성능을 향상시키면 더 시도해보자.) 
            몇 번 반복해서 하면, 학습률은 결국 $\eta = 1.0$ 과 같이 될 것이다. 
            (아마도 $3.0$이 적절할 것이다.) 
            이 학습률 값은 이전에 한 실험에서 본 값과 비슷하다. 
            따라서 하이퍼파라미터를 잘 못 선택했더라도 하이퍼파라미터 선택을 바꿀 정보는 주어진다. 
          </p>

          <p>
            일반적으로 신경망을 디버깅하는 것은 꽤나 힘든 문제이다. 
            하이퍼파라미터의 초기 선택이 무작위한 선택보다 좋은 결과를 내지 못할 때 특히 그렇다. 
            이전에 봤던 신경망 구조와 같이 은닉층에 $30$ 개의 뉴런이 있지만 학습률을 $\eta = 100.0$으로 바꿔 보자. 
            
            <pre class="prettyprint linenums"><code class="language-python">>>> net = network.Network([784, 30, 10])
>>> net.SGD(training_data, 30, 10, 100.0, test_data=test_data)</code></pre>

            이 점에서 우리는 너무 멀리 갔고 학습률은 너무 높다. 

            <pre class="prettyprint linenums"><code class="language-python">Epoch 0: 1009 / 10000
Epoch 1: 1009 / 10000
Epoch 2: 1009 / 10000
Epoch 3: 1009 / 10000
...
Epoch 27: 982 / 10000
Epoch 28: 982 / 10000
Epoch 29: 982 / 10000</code></pre>

            이 문제를 처음 봤다고 상상해보자. 
            물론 이 전의 실험에서 본 것처럼 우리가 해야할 것은 학습률을 감소시키는 것이다. 
            하지만 처음으로 이 문제를 마주쳤다면 출력에서 어떻게 해야할지 알려줄 수 있는 것이 많이 없다. 
            학습률에 대해 고민 할 수도 있지만 신경망의 다른 모든 면들을 생각할지도 모른다. 
            신경망이 학습하는 것을 어렵게 만드는 방법으로 가중치와 편향을 초기화했다고 생각할 수도 있다. 
            또는 의미있는 학습을 하기 위한 학습 데이터가 충분하지 못했다고 생각할 수도 있다. 
            충분한 세대동안 실행하지 않았나? 
            또는 이 구조를 가지는 신경망은 손글씨 숫자를 인식하기 위해 학습하는 것이 불가능한가? 
            학습률이 너무 낮은 것일까? 
            아니면 학습률이 너무 높은 걸까?
            처음으로 이 문제를 마주하면 확신할 수 없다. 
          </p>

          <p>
            신경망을 디버깅하는 것은 중요하고 일반적인 프로그래밍 처럼 디버깅을 하는데 기술이 필요하다는 것이 이 문제를 벗어나기 위한 교훈이다. 
            신경망에서 좋은 결과를 얻으려면 디버깅 기술을 배워야 한다. 
            더 일반적으로 좋은 하이퍼파라미터와 좋은 구조를 선택하는 방법을 스스로 개발해야한다. 
            위에서 하이퍼파라미터를 선택한 방법을 포함하여 책 전반에 걸쳐 이러한 내용을 상세히 다루겠다. 
          </p>

          <br />
          <h2>예제</h2>

          <p>
            <ul>
              <li>
                <p>
                  단 두 개의 층을 가지는 신경망을 만들어라. 
                  입력과 출력 층을 가지며 각각 $784$ 개와 $10$ 개의 뉴런을 가진다.  
                  은닉층은 가지지 않는다. 
                  확률적 경사 하강을 이용하여 신경망을 학습시켜라. 
                  얻을 수 있는 분류의 정확도는 얼마인가? 
                </p>
              </li>
            </ul>
          </p>

          <p>
            앞서 MNIST 데이터를 로드하는 방법을 상세히 다루지 않고 넘어갔다. 
            이는 꽤 직관적이다. 
            완성도를 위해 아래 코드가 있다. 
            MNIST 데이터를 저장하는데 사용된 데이터 구조는 문서화 문자열에 표기되어있다. 
            이는 Numpy <code>ndarray</code> 객체의 튜플과 리스트이다. 
            (<code>ndarrays</code>를 벡터로 생각해도 된다.)
          </p>

          <p>
            <pre class="prettyprint linenums"><code class="language-python">"""
mnist_loader
~~~~~~~~~~~~ 
  
A library to load the MNIST image data.  For details of the data
structures that are returned, see the doc strings for ``load_data``
and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the
function usually called by our neural network code.
"""

#### Libraries
# Standard library
import cPickle
import gzip

# Third-party libraries
import numpy as np  
   
def load_data():
    """Return the MNIST data as a tuple containing the training data,
    the validation data, and the test data.
    
    The ``training_data`` is returned as a tuple with two entries.
    The first entry contains the actual training images.  This is a
    numpy ndarray with 50,000 entries.  Each entry is, in turn, a
    numpy ndarray with 784 values, representing the 28 * 28 = 784
    pixels in a single MNIST image.
    
    The second entry in the ``training_data`` tuple is a numpy ndarray
    containing 50,000 entries.  Those entries are just the digit
    values (0...9) for the corresponding images contained in the first
    entry of the tuple.
    
    The ``validation_data`` and ``test_data`` are similar, except
    each contains only 10,000 images.
    
    This is a nice data format, but for use in neural networks it's
    helpful to modify the format of the ``training_data`` a little.
    That's done in the wrapper function ``load_data_wrapper()``, see
    below.
    """
    f = gzip.open('../data/mnist.pkl.gz', 'rb')
    training_data, validation_data, test_data = cPickle.load(f)
    f.close()
    return (training_data, validation_data, test_data)
    
def load_data_wrapper():
    """Return a tuple containing ``(training_data, validation_data,
    test_data)``. Based on ``load_data``, but the format is more
    convenient for use in our implementation of neural networks.
    
    In particular, ``training_data`` is a list containing 50,000
    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray
    containing the input image.  ``y`` is a 10-dimensional
    numpy.ndarray representing the unit vector corresponding to the
    correct digit for ``x``.
    
    ``validation_data`` and ``test_data`` are lists containing 10,000
    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional
    numpy.ndarry containing the input image, and ``y`` is the
    corresponding classification, i.e., the digit values (integers)
    corresponding to ``x``.
    
    Obviously, this means we're using slightly different formats for
    the training data and the validation / test data.  These formats
    turn out to be the most convenient for use in our neural network
    code."""
    tr_d, va_d, te_d = load_data()
    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]
    training_results = [vectorized_result(y) for y in tr_d[1]]
    training_data = zip(training_inputs, training_results)
    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]
    validation_data = zip(validation_inputs, va_d[1])
    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]
    test_data = zip(test_inputs, te_d[1])
    return (training_data, validation_data, test_data)
    
def vectorized_result(j):
    """Return a 10-dimensional unit vector with a 1.0 in the jth
    position and zeroes elsewhere.  This is used to convert a digit
    (0...9) into a corresponding desired output from the neural
    network."""
    e = np.zeros((10, 1))
    e[j] = 1.0
    return e</code></pre>

            작성한 프로그램은 꽤 좋은 결과를 낸다고 앞서 말했다. 
            이는 무엇을 의미할까? 
            무엇과 비교해서 좋다는 말일까? 
            성능이 좋다는 의미를 이해하기 위해 비교할 만한 간단한 (신경망이 아닌) 기준 테스트를 하는 것이 유용하다. 
            물론 가장 간단한 기준점은 무작위로 숫자를 예측하는 것이다. 
            그것은 약 $10%$ 의 시간이 된다. 우리는 그것보다 훨씬 잘하고 있다.  
          </p>

          <p>
            조금 더 의미있는 기준점은 무엇일까? 
            간단한 아이디어를 적용해보자. 
            이미지가 얼마나 어두운지 살펴보자. 
            예를 들어 $2$ 의 이미지는 $1$ 의 이미지보다 조금 더 어두울 것이다. 
            다음의 예시에서 보는 것처럼 더 많은 픽셀이 검은색이기 때문이다. 

            <br /><br />
            <img class="contentimg" src="./images/chapter1/mnist_2_and_1.png" alt="digits" width="200px">
            <br /><br />

            이는 각 숫자 $0, 1, 2,\ldots, 9$ 에 대한 어두운 정도의 평균을 학습데이터를 사용해 계산하라고 제안한다. 
            새로운 이미지가 주어지면 이미지가 얼마나 어두운지 계산하고 어떤 수가 가장 가까운 평균값을 가지는지 추측한다. 
            이는 간단한 과정이고 코드를 작성하기쉽기 때문에 코드를 보여주지는 않을 것이다. 
            만약 코드를 보고 싶으면 <a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py">Github 저장소</a>에서 볼 수 있다. 
            무작위로 추측하는 방법보다 개선할 수 있는 방법이다. $10,000$ 개의 테스트 이미지 중 $2,225$ 개를 맞출 수 있다. 즉 정확도는 $22.25%$ 이다. 
          </p>

          <p>
            $20$ 에서 $50%$ 의 정확도를 가지는 다른 아이디어를 찾는 것은 어렵지 않다. 
            조금만 찾아보면 $50%% 가 넘는 것을 금방 찾을 수 있다. 
            하지만 더 높은 정확도를 얻으려면 잘 알려진 머신 러닝 알고리즘을 사용해야 한다. 
            가장 잘 알려진 알고리즘 중 하나인 서포트 벡터 머신(support vector machine, SVM)을 사용해보자. 
            SVM을 처음보더라도 걱정하지 않아도 된다. SVM이 어떻게 동작하는지 자세히 이해할 필요는 없다. 
            대신 <a href="https://scikit-learn.org/stable/">scikit-lear</a>n이라 불리는 파이썬 라이브러리를 사용할 것이다. 
            이는 <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM</a>이라 알려진 SVM에 대한 C 기반 알고리즘을 위한 파이썬 인터페이스를 제공한다. 
          </p>

          <p>
            기본 설정 값을 이용해 scikit-learn의 SVM 분류기를 실행하면 $10,000$ 개의 테스트 이미지 중 $9,435$ 개를 맞춘다. 
            (코드는 <a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py">여기</a>서 이용할 수 있다.) 
            이미지가 얼마나 어두운지에 따라 분류하는 방법보다 훨씬 큰 성능 개선을 보인다. 
            이는 SVM의 성능이 신경망과 비슷하며 약간 안좋을 뿐이다. 
            책의 뒷부분에서 SVM보다 훨씬 뛰어난 성능을 가지는 신경망을 개선시키는 새로운 기술을 도입할 것이다. 
          </p>

          <p>
            하지만 이것이 이야기의 끝은 아니다. 
            SVM에 대한 scikit-learn의 기본 설정값의 결과가 $10,000$ 개 중 $9,435$ 의 결과이다. 
            SVM은 조정할 수 있는 매개 변수가 많으며 이 좋은 성능을 향상시키는 매개 변수를 탐색할 수 있다. 
            여기서 이 탐색을 상세히 다루지 않지만 더 알고싶다면 <a href="https://peekaboo-vision.blogspot.com/">안드레아스 뮐러</a>(Andreas Muller)의 <a href="https://peekaboo-vision.blogspot.com/2010/09/mnist-for-ever.html">블로그 글</a>을 한 번 보자.
            뮐로는 SVM 매개변수 최적화를 통해 성능을 $98.5%$의 정확도로 높였다. 
            즉, 잘 설정된 SVM은 70 개 중 한 개의 오차만 발생시킨다. 
            이는 엄청나다. 
            신경망은 더 좋은 성능을 낼 수 있을까? 
          </p>

          <p>
            사실 신경망은 더 좋은 성능을 낼 수 있다. 
            현재 잘 설계된 신경망은 SVM을 포함해 MNIST를 푸는 다른 모든 기술의 성능을 뛰어넘었다. 
            현재(2013)의 기록은 $10,000$개의 이미지중 $9,979$개의 이미지를 정확히 분류했다. 
            이는 <a href>Li Wan</a>, <a href="https://www.matthewzeiler.com/">Matthew Zeiler</a>, Sixin Zhang, <a href="http://yann.lecun.com/">Yann LeCun</a>, <a href="https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php">Rob Fergus</a>가 이룬 업적이다. 
            이 책의 뒷 부분에서 그들이 사용한 기술을 살펴보겠다. 
            그 수준에서 성능은 인간과 거의 동등하며 아래처럼 MNIST 이미지의 몇몇은 인간조차 확신을가지고 인식하기 어려우므로 인간보다 더 뛰어나다는 주장도 있다. 

            <br /><br />
            <img class="contentimg" src="./images/chapter1/mnist_really_bad_images.png" alt="digits" width="500px">
            <br /><br />

            위의 숫자는 분류하기에 어렵다. 
            MNIST 데이터 셋 중 위와 같은 이미지를 신경망이 $10,000$ 개의 테스트 이미지중 $21$ 개를 제외하고 모두 정확히 분류할 수 있다는 것은 놀랍다. 
            보통 프로그램을 작성할 때 MNIST 숫자 인식과 같은 복잡한 문제를 풀려면 아주 정교한 알고리즘이 필요할 것이라고 믿어왔다. 
            방금 말한 Wan et al 논문의 신경망은 이 장에서 살펴본 알고리즘의 변형인 아주 간단한 알고리즘을 포함한다. 
            모든 복잡도는 학습 데이터를 통해 자동으로 학습된다. 
            어떤 면에서 우리의 결과와 조금더 정교한 논문에서의 결과의 교훈은 어떤 문제에 대한 다음과 같은 사실이다. 
          </p>

          <p style="text-align: center">
            복잡한 알고리즘 $\leq$ 간단한 학습 알고리즘 $+$ 좋은 학습 데이터 
          </p>

          <br />
          <h2>딥러닝에 대하여</h2>
          <hr>

          <p>
            신경망이 좋은 성능을 내지만 이 성능은 한편으론 다소 이해하기 힘들다. 
            신경망에서 가중치와 편향은 자동으로 찾는다. 
            그리고 이것은 신경망이 어떻게 동작하는지 즉각적인 설명을 하지 못한다. 
            신경망이 손글씨를 분류하는 원리를 이해하기 위한 방법이 있을까? 
            그런 원리가 있다면 우리는 더 좋은 성능을 낼 수 있을까?
          </p>

          <p>
            문제를 더 분명히하기 위해 이제부터 수십년 동안 신경망이 인공지능(artificial intelligence, AI)로 이어진다고 가정하자. 
            그렇게 똑똑한 신경망이 어떻게 동작하는지 이해할 수 있을까? 
            가중치와 편향은 자동으로 학습되므로 우리가 이해하지 못해 신경망은 우리에게 불투명한 존재일 것이다. 
            AI 연구의 초창기에 사람들은 AI를 만드는 노력이 지능 뒤에 숨겨진 원리를 이해하고 인간 두뇌의 기능을 이해하는데 도움이 될 것이라는 희망이 있었다. 
            하지만 결과는 두뇌와 인공지능이 어떻게 동작하는지 이해하지 못한 채로 끝났다. 
          </p>

          <p>
            이 문제를 다루기 위해 증거를 가늠하는 수단으로 이 장의 앞부분에서 이야기 한 인공 뉴런의 해석으로 돌아가 보자. 
            우리는 주어진 이미지가 사람의 얼굴인지 아닌지를 판별하고 싶다고 가정하자. 
          
            <br />
            <a href="https://commons.wikimedia.org/wiki/File:Kangaroo_ST_03.JPG" ><img class="contentimg" src="http://neuralnetworksanddeeplearning.com/images/Kangaroo.JPG" alt="digits" height="180px" style="float:left; margin:10px"></a>
            <a href ="https://commons.wikimedia.org/wiki/File:Albert_Einstein_at_the_age_of_three_(1882).jpg"><img class="contentimg" src="http://neuralnetworksanddeeplearning.com/images/Einstein_crop.jpg" alt="digits" height="180px" style="float:left; margin:10px"></a>
            <a href="https://commons.wikimedia.org/wiki/File:The_Hubble_eXtreme_Deep_Field.jpg"><img class="contentimg" src="http://neuralnetworksanddeeplearning.com/images/hubble.jpg" alt="digits" height="180px" style="float:left; margin:10px"></a>
            <br /><br />
          </p>

          <p style="clear:left">
            손글씨 인식 문제를 풀었던 방법으로 이 문제를 풀 수 있다. 
            신경망의 입력으로 이미지의 픽셀을 사용하고 신경망의 출력으로 하나의 뉴런을 사용해 "사람 얼굴이다", "사람 얼굴이 아니다"를 표시한다. 
          </p>

          <p>
            학습 알고리즘을 사용하지 않고 이 문제를 푼다고 가정해보자. 
            대신 적절한 가중치와 편향을 선택하여 직접 신경망을 설계해볼 것이다. 
            어떻게 할 수 있을까? 
            신경망에 대한 생각을 잠시 접어두자. 
            직접 해볼 수 있는 방법은 문제를 여러개의 문제로 분해하는 것이다. 
            이미지의 왼쪽 위에 눈이 있나?
            이미지 가운데 코가 있나? 
            이미지 중간 아랫 부분에 입이 있나? 
            윗 부분에는 머리카락이 있나? 
          </p>

          <p>
            질문 중 몇 개에 대한 답이 "있다"이거나 "있는 것 같다"이면 이미지가 사람 얼굴이라고 결론 지을 수 있다. 
            반대로 질문에 대한 답이 "없다"이면 이미지는 사람 얼굴이 아닐 것이다. 
          </p>

          <p>
            물론 이는 무식한 방법일 수 있으며 많은 결함이 있다. 
            사람이 대머리일 수도 있으므로 머리카락이 없을 수 있기 때문이다. 
            얼굴중 일부만 볼 수 있거나 얼굴 각도가 다른 경우 얼굴의 특징 중 일부분은 가려질 수 있다. 
            하지만 이러한 방법은 신경망을 이용해서 하위 문제를 풀 수 있다면 얼굴 탐지를 위한 신경망을 하위 문제의 신경망 조합으로 만들 수 있다는 것을 보여준다. 
            아래 가능한 구조가 나타나 있다. 
            사각형은 하위 문제를 표시한다. 
            얼굴 탐지 문제를 푸는 현실적인 방법은 아니다. 
            하지만 신경망이 어떻게 동작하는지에 대한 직관을 키울 수 있다. 
            다음은 신경망 구조이다. 

            <br /><br />
            <img class="contentimg"  src="./images/chapter1/tikz14.png" alt="digits" width="600px">
            <br /><br />

            하위 신경망이 분해될 수도 있다. 
            다음 질문 "왼쪽 위에 눈이 있는가?"을 생각해보자. 
            이는 다음과 같은 물음으로 분해될 수 있다. 
            "눈썹이 있는가?" 
            "속눈썹이 있나?" 
            "홍채가 있나?"와 같은 질문으로 분해된다. 
            물론 이러한 질문은 위치에 대한 정보를 가지고 있어야 한다. 
            "이미지의 왼쪽 위에 눈썹이 있으며 그 아래 홍채가 있나?" 
            하지만 간단하게 생각해보자. 
            "이미지의 왼쪽 위에 눈이 있나?"라는 질문에 대한 답을 하는 신경망은 다음과 같이 분해될 수 있다. 

            <br /><br />
            <img class="contentimg"  src="./images/chapter1/tikz15.png" alt="digits" width="600px">
            <br /><br />

            이런 질문은 계속해서 더 많은 층으로 나눌 수 있다. 
            궁극적으로 하위 신경망이 질문에 답하는 것은 매우 단순하여 하나의 픽셀 수준에서 쉽게 답할 수 있다. 
            예를 들어 이 질문은 이미지의 어떤 부분에서 매우 단순한 모양의 존재 유무를 묻는 것이다. 
            이미지의 픽셀에 연결한 하나의 뉴런이 이러한 질문에 답할 수 있다. 
          </p>

          <p>
            이미지가 사람 얼굴을 보여주는가와 같은 복잡한 문제를 픽셀 수준에서 답할 수 있는 단순한 질문으로 분해하는 신경망이 최종 결과이다. 
            이는 다층의 신경망을 통해 이루어진다. 
            앞부분에 있는 층은 입력 이미지에 대한 단순하고 구체적인 질문에 답한다. 
            뒤에 있는 층은 더 복잡하고 추상적인 개념에 대한 계층 구조를 형성한다. 
            두 개 이상의 은닉층을 가지는 이러한 다층 구조의 신경망을 심층 신경망(deep neural network)라 한다. 
          </p>

          <p>
            물론 어떻게 재귀적으로 하위 문제로 분해하는지 설명하지 않았다. 
            직접 신경망의 가중치와 편향을 설계하는 것은 실용적이지 않다. 
            대신 신경망이 자동으로 가중치와 편향을 학습하도록 학습 알고리즘을 사용한다. 
            즉 학습 데이터에서 개념의 계층 구조를 학습한다. 
            1980년대와 90년대의 연구자들은 심층 신경망을 학습시키기 위해 확률적 경사 하강법과 역전파 알고리즘을 사용했다. 
            하지만 몇몇 구조를 제외하고는 좋은 성과를 내지 못했다. 
            신경망이 학습을 하지만 매우 느렸고 실제로 사용할 수 없을 정도로 느렸다. 
          </p>

          <p>
            2006년 이후 심층 신경망을 학습시킬 수 있는 몇몇 기술들이 개발되었다. 
            이 딥러닝 기술은 확률적 경사 하강 알고리즘과 역전파 알고리즘을 기반으로 하고 있지만 새로운 아이디어를 도입했다. 
            이러한 기술을 통해 훨씬 더 크고 깊은 신경망을 학습시킬 수 있었다. 
            현재 사람들은 일상적으로 5개에서 10개의 은닉층을 가지는 신경망을 훈련시킨다. 
            그리고 단 하나의 은닉층을 가지는 얕은 신경망보다 심층 신경망의 성능이 많은 문제에서 성능이 훨씬 좋다. 
            물론 심층 신경망이 개념에 대한 복잡한 계층 구조를 만들 수 있는 능력이 있기 때문이다. 
            이는 전통적인 프로그래밍 언어가 모듈식 디자인과 아이디어를 이용해 복잡한 프로그램을 만들수 있었던 것과 비슷하다. 
            심층 신경망과 얕은 신경망의 관계는 함수 호출을 할 수 있는 프로그래밍 언어와 함수 호출을 할 수 없는 언어의 관계와 닮아 있다. 
            전통적인 프로그래밍에서의 추상화와 신경망에서의 추상하는 다르지만 중요한 것은 똑같다. 
          </p>
        </div>
      </div>

      <div class="rightcolumn">
        
        <div class="card">
          <h2>저자</h2>
          <h3><a href="http://michaelnielsen.org/">Michael A. Nielsen</a></h3>
        </div>

        <div class="card">
            <h2>역자</h2>
            <h3>김시현</h3>
            <p><a href="https://github.com/sihyeon-kim"><img src="images/GitHub-Mark-32px.png" alt="Github" width="17" height="17">&nbsp;sihyeon-kim</a></p>
            <p><a href="mailto:sihyeonkim0923@gmail.com">&nbsp;sihyeonkim0923@gmail.com</a></p>
        </div>

        <div class="card">
            <h2>참고 자료</h2>
            <p><a href="https://twitter.com/michael_nielsen">저자(Michael A. Nielsen) 트위터</a></p>
            <p><a href="faq.html">자주 묻는 질문</a></p>
            <p>
              <a href="https://github.com/mnielsen/neural-networks-and-deep-learning">
              저자(Michael A. Nielsen) 코드 저장소</a>
            </p>
            <p><a href="http://www.deeplearningbook.org/">Deep Learning</a>, book by Ian Goodfellow, Yoshua Bengio, and Aaron Courville</p>
            <p><a href="http://cognitivemedium.com/">cognitivemedium.com</a></p>
            <p>한글 글꼴(korean fonts): <a href="https://help.naver.com/support/contents/contents.help?serviceNo=1074&categoryNo=3497">나눔 글꼴</a></p>
        </div>
      </div>
    </div>
    
    <div class="footer">

      <p> 
        In academic work,
        please cite this book as: Michael A. Nielsen, "Neural Networks and
        Deep Learning", Determination Press, 2015
        
        <br/>
        <br/>
        
        This work is licensed under a 
        <a rel="license"  href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB">
          Creative Commons Attribution-NonCommercial 3.0 Unported License
        </a>.  This means you're free to copy, share, and
        build on this book, but not to sell it.  If you're interested in
        commercial use, please <a href="mailto:mn@michaelnielsen.org">contact me(Michael A. Nielsen)</a>.
      </p>

      <br/>

      <p>
        학업적으로 이용 시 다음과 같이 인용해 주세요: Michael A. Nielsen, "Neural Networks and
        Deep Learning", Determination Press, 2015
        <br/><br/>
        <a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/">
          <img alt="크리에이티브 커먼즈 라이선스" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/3.0/88x31.png" />
        </a>
        <br />이 저작물은 
        <a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/">크리에이티브 커먼즈 저작자표시-비영리 3.0 Unported 라이선스</a>
        에 따라 이용할 수 있습니다.
        <br /><br />
        상업적 이용을 원하면, <a href="mailto:mn@michaelnielsen.org">저자(Michael A. Nielsen)에게 연락을 주세요.</a>
        <br /><br />
        마지막 깁고 더함: 19/06/21
      </p>
    </div>

  </body>

</html>
